\documentclass{book}

\usepackage{fontspec} % used to import Calibri
\usepackage{anyfontsize} % used to adjust font size

% needed for inch and other length measurements
% to be recognized
\usepackage{calc}

% for colors and text effects as is hopefully obvious
\usepackage[dvipsnames]{xcolor}
\usepackage{soul}

% control over margins
\usepackage[margin=1in]{geometry}
\usepackage[strict]{changepage}

\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{bm}

\usepackage[scr=rsfso, scrscaled=.96]{mathalpha}

\usepackage{amssymb} % originally imported to get the proof square
\usepackage{xfrac}
\usepackage[overcommands]{overarrows} % Get my preferred vector arrows...
\usepackage{relsize}

% Just am using this to get a dashed line in a table...
% Also you apparently want this to be inactive if you aren't
% using it because it slows compilation.
\usepackage{arydshln} \ADLinactivate 
\newenvironment{allowTableDashes}{\ADLactivate}{\ADLinactivate}

\usepackage{graphicx}
\graphicspath{{./158_Images/}}

\usepackage{tikz}
   \usetikzlibrary{arrows.meta}
   \usetikzlibrary{graphs, graphs.standard}

\usepackage{quiver} %commutative diagrams


\newfontfamily{\calibri}{Calibri}
\setlength{\parindent}{0pt}
\definecolor{RawerSienna}{HTML}{945D27}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%Arrow Commands:

% Thank you Bernard, gernot, and Sigur who I copied this from:
% https://tex.stackexchange.com/questions/364096/command-for-longhookrightarrow
\newcommand{\hooklongrightarrow}{\lhook\joinrel\longrightarrow}
\newcommand{\hooklongleftarrow}{\longleftarrow\joinrel\rhook}
\newcommand{\hookxlongrightarrow}[2][]{\lhook\joinrel\xrightarrow[#1]{#2}}
\newcommand{\hookxlongleftarrow}[2][]{\xleftarrow[#1]{#2}\joinrel\rhook}

% Thank you egreg who I copied from:
% https://tex.stackexchange.com/questions/260554/two-headed-version-of-xrightarrow
\newcommand{\longrightarrowdbl}{\longrightarrow\mathrel{\mkern-14mu}\rightarrow}
\newcommand{\longleftarrowdbl}{\leftarrow\mathrel{\mkern-14mu}\longleftarrow}

\newcommand{\xrightarrowdbl}[2][]{%
  \xrightarrow[#1]{#2}\mathrel{\mkern-14mu}\rightarrow
}
\newcommand{\xleftarrowdbl}[2][]{%
  \leftarrow\mathrel{\mkern-14mu}\xleftarrow[#1]{#2}
}

\newcommand{\MRoman}[1]{%
   \textrm{\MakeUppercase{\romannumeral #1}}%
}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\newcommand{\learnToSpot}[1]{{\color{Red}#1}}

\newcommand{\hOne}{%
   \color{Black}%
   \fontsize{14}{16}\selectfont%
}
\newcommand{\hTwo}{%
\color{MidnightBlue}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\hThree}{%
   \color{PineGreen!85!Orange}
   \fontsize{12}{14}\selectfont%
}
\newcommand{\myComment}{%
   \color{RawerSienna}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\teachComment}{
   \color{Orange}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\exOne}{%
   \color{Purple}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\exTwo}{%
   \color{Purple}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\exP}{%
   \color{Purple}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\exTwoP}{%
   \color{RedViolet}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\exPP}{%
   \color{RedViolet}%
   \fontsize{12}{14}\selectfont%
}
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\newcommand{\cyPen}[1]{{\vphantom{.}\color{Cerulean}#1}}
\newcommand{\redPen}[1]{{\vphantom{.}\color{Red}#1}}

\newenvironment{myIndent}{%
   \begin{adjustwidth}{2.5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myDindent}{%
   \begin{adjustwidth}{5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myTindent}{%
   \begin{adjustwidth}{7.5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myConstrict}{%
   \begin{adjustwidth}{2.5em}{2.5em}%
}{%
   \end{adjustwidth}%
}

\newcommand{\udefine}[1]{{%
   \setulcolor{Red}%
   \setul{0.14em}{0.07em}%
   \ul{#1}%
}}

\newcommand{\blab}[1]{\textbf{#1}}

\newcommand{\uuline}[2][.]{%
{\vphantom{a}\color{#1}%
\rlap{\rule[-0.18em]{\widthof{#2}}{0.06em}}%
\rlap{\rule[-0.32em]{\widthof{#2}}{0.06em}}}%
#2}

\newcommand{\pprime}{{\prime\prime}}
\newcommand{\suchthat}{ \hspace{0.3em}s.t.\hspace{0.3em}}
\newcommand{\rea}[1]{\mathrm{Re}(#1)}
\newcommand{\ima}[1]{\mathrm{Im}(#1)}
\newcommand{\comp}{\mathsf{C}}
\newcommand{\card}{\mathrm{card}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\myHS}{ \hspace{0.5em}}

\newcommand{\myId}{\mathrm{Id}}
\newcommand{\myIm}{\mathrm{im}}
\newcommand{\myObj}{\mathrm{Obj}}
\newcommand{\myHom}{\mathrm{Hom}}
\newcommand{\myEnd}{\mathrm{End}}
\newcommand{\myAut}{\mathrm{Aut}}

\newcommand{\mcateg}[1]{{\bm{\mathsf{#1}}}}

% Thank you Gonzalo Medina and Moriambar who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/74125/how-do-i-put-text-over-symbols%
\newcommand{\myequiv}[1]{\stackrel{\mathclap{\mbox{\footnotesize{$#1$}}}}{\equiv}}

% Thank you chs who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/89821/how-to-draw-a-solid-colored-circle%
\newcommand{\filledcirc}[1][.]{\ensuremath{\hspace{0.05em}{\color{#1}\bullet}\mathllap{\circ}\hspace{0.05em}}}

%Thank you blerbl who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/25348/latex-symbol-for-does-not-divide
\newcommand{\ndiv}{\hspace{-0.3em}\not|\hspace{0.35em}}

\newcommand{\mySepOne}[1][.]{%
   {\noindent\color{#1}{\rule{6.5in}{1mm}}}\\%
}
\newcommand{\mySepTwo}[1][.]{%
   {\noindent\color{#1}{\rule{6.5in}{0.5mm}}}\\%
}

\newenvironment{myClosureOne}[2][.]{%
   \color{#1}%
   \begin{tabular}{|p{#2in}|} \hline \\%
}{%
   \\ \hline \end{tabular}%
}

\newcommand{\retTwo}{\hfill\bigbreak}

\newcommand{\mHeader}[1]{{
   \color{Black}%
   \fontsize{20}{18}\selectfont%
   #1\retTwo
}}


\title{Math 188 Notes (Professor: Steven Sam)}
\author{Isabelle Mills}

\begin{document}
\maketitle{}
\setul{0.14em}{0.07em}
\calibri

\hOne
\mHeader{Lecture 1 Notes: 9/27/2024}

\blab{Linear Recurrence Relations:}\\
A sequence $(a_n)_{n \geq 0}$ satisfies a \udefine{linear recurrence relation of order $d$} if there exists\\ $c_1, \ldots, c_d$ with $c_d \neq 0$ such that for all $n \geq d$:

{\centering $a_n = c_1a_{n-1} + c_2a_{n-2} + \ldots + c_da_{n-d}$\par}


\begin{myTindent}\begin{myTindent}\myComment
   (For $0 \leq n < d$, we usually explicitely specify $a_n$.)\retTwo
\end{myTindent}\end{myTindent}

To start this course, we're gonna discuss finding explicit (non-recursive) solutions.\retTwo

Firstly, if $d = 1$, then this problem is easy. We can just plug in previous elements repeatedly to get that:

{\centering $a_n = c_1a_{n-1} = c_1^{\vphantom{|}2}a_{n-2} = \ldots = c_1^{\vphantom{|}n}a_0$ \retTwo\par}

If $d = 2$, then plugging in previous elements doesn't help us really anymore. So how do we solve this problem now?\\

\begin{myIndent}\hTwo
   \blab{Theorem:} Consider the \udefine{characteristic polynomial} $t^2 - c_1t - c_2$ and let $r_1, r_2$\\ be the roots of that polynomial. If $r_1 \neq r_2$, then there exists $\alpha_1, \alpha_2$ such that\\ $a_n = \alpha_1r_1^{\vphantom{|}n} + \alpha_2r_2^{\vphantom{|}n}$ for all $n \geq 0$.\retTwo

   To solve for $\alpha_1$ and $\alpha_2$, plug in different values of $n$ into our equation. Since $r_1 \neq r_2$, we know the below linear system has a unique solution:

   {\centering $ 
   \begin{matrix}
      a_0 = \alpha_1 + \alpha_2 \\ a_1 = \alpha_1 r_1 + \alpha_2 r_2
   \end{matrix}$ \retTwo\par}
\end{myIndent}

Now backing up, why does the above method work?\\
\begin{myIndent}\hTwo

   \blab{Approach 1: (Vector Spaces)}\\
   The set of sequences $(a_n)_{n\geq 0}$ form a vector space. Furthermore given any constants $c_1$ and $c_2$, we know that the set of sequences satisfying $a_n = c_1a_{n-1} + c_2a_{n-2}$ for all $n \geq 2$ is a subspace.
   
   \begin{myIndent}\hThree
      Proof:\\
      Suppose $(a_n)$ and $(b_n)$ both satisfy that $a_n = c_1a_{n-1} + c_2a_{n-2}$ and\\ $b_n = c_1b_{n-1} + c_2b_{n-2}$. Then given any constants $\gamma$ and $\delta$, we have that:

      {\centering $(\gamma a_n + \delta b_n) = c_1(\gamma a_{n-1} + \delta b_{n-1}) + c_2(\gamma a_{n-2} + \delta b_{n-2})$ \retTwo\par}

      Hence, all linear combinations of any two sequences satisfying our linear\\ recurrence relation also satisfies our linear recurrence relation.\retTwo
   \end{myIndent}

   Now what our above theorem is stating is that the sequences $(r_1^{\vphantom{|}n})$ and $(r_2^{\vphantom{|}n})$ span the subspace of solutions to our linear recurrence relation.\retTwo

   To see this, first note that $(r_1^{\vphantom{|}n})$ and $(r_2^{\vphantom{|}n})$ satisfy our recurrence relation.
   \begin{myIndent}\hThree
      If $n \geq 2$, then $r_i^{\vphantom{|}n} - c_1r_i^{\vphantom{|}n-1} - c_2r_i^{\vphantom{|}n-2} = r_i^{\vphantom{|}n-2}(r_i^{\vphantom{|}2} - c_1r_i - c_2) = r_i^{\vphantom{|}n-2} (0)$.\\ Hence, we know that $r_i^{\vphantom{|}n} = c_1r_i^{\vphantom{|}n-1} + c_2r_i^{\vphantom{|}n-2}$ for all $n \geq 2$.\newpage
   \end{myIndent}

   Also, since we assumed $r_1 \neq r_2$, we know that $(r_1^{\vphantom{|}n})$ is linearly independent to $(r_2^{\vphantom{|}n})$. And finally, as mentioned before, we can solve a linear system of equations to find\\ [-2pt] coffecients for a linear combination of $(r_1^{\vphantom{|}n})$ and $(r_2^{\vphantom{|}n})$ equal to any other sequence satisfying our recurrence relation.\retTwo

   \blab{Approach 2: (Formal Power Series)}\\
   Define the power series $A(x) = \sum\limits_{n \geq 0}a_nx^n$. We call $A(x)$ a \udefine{generating function} of\\ [-10pt] the sequence $(a_n)$.
   
   
   \begin{myTindent}\begin{myIndent}\teachComment
      (We'll treat the formal power series more rigorously later...)\retTwo
   \end{myIndent}\end{myTindent}

   Now note that:\\ [-10pt]
   \begin{myIndent}\hThree
      \begin{tabular}{l}
         $ A(x) = a_0 + a_1x + \sum\limits_{n \geq 2} a_nx^n$\\ [14pt]
         $ \phantom{A(x)} = a_0 + a_1x + \sum\limits_{n \geq 2} (c_1a_{n-1} + c_2a_{n-2})x^n$\\ [14pt]
         $ \phantom{A(x)} = a_0 + a_1x + c_1\sum\limits_{n \geq 2} a_{n-1}x^n + c_2\sum\limits_{n \geq 2}a_{n-2}x^n$\\ [14pt]
         $\phantom{A(x)} = a_0 + a_1x + c_1(A(x) - a_0)x + c_2(A(x))x^2$
      \end{tabular}\retTwo
   \end{myIndent}

   Isolating $A(x)$, we get the equation: $A(x) = \dfrac{a_0 + a_1x - a_0c_1x}{1 - c_1x - c_2x^2}$.\retTwo

   Next, let's do fraction decomposition on our equation for $A(x)$.
   \begin{myIndent}\hThree
      \blab{Issue:} We defined $r_1$ and $r_2$ as the roots of $t^2 - c_1t - c_2 = (t - r_1)(t - r_2)$.\retTwo

      \blab{Trick:} Plug in $t = \frac{1}{x}$. That way, we have that:
      
      {\centering$x^{-2} - c_1x^{-1} - c_2 = (x^{-1} - r_1)(x^{-1} - r_2)$.\retTwo\par}
      
      After that, multiply both sides of our equation by $x^2$ to get that:

      {\centering $ 1 - c_1x - c_2x^2 = (1 - r_1x)(1 - r_2x)$ \retTwo\par}
   \end{myIndent}

   Since we're assuming $r_1 \neq r_2$, we know that for some constants $\alpha_1$ and $\alpha_2$, we have that:

   {\centering $A(x) = \dfrac{\alpha_1}{1 - r_1x} + \dfrac{\alpha_2}{1 - r_2x} $ \retTwo\par}

   
   \begin{myTindent}\begin{myIndent}\teachComment
      (If $r_1 = r_2$, then this step is where things will go differently.)\retTwo
   \end{myIndent}\end{myTindent}

   Now finally, we can rewrite $\frac{\alpha_1}{1 - r_1x}$ as the geometric series $\alpha_1 \sum\limits_{n \geq 0}(r_1x)^n$. Doing\\ [-6pt] likewise with $\frac{\alpha_2}{1 - r_2x}$, we get that:

   {\center $A(x) = \sum\limits_{n \geq 0} a_n x^n = \alpha_1 \sum\limits_{n \geq 0}(r_1x)^n + \alpha_2 \sum\limits_{n \geq 0}(r_2x)^n = \sum\limits_{n \geq 0}(\alpha_1r_1^{\vphantom{|}n} + \alpha_2r_2^{\vphantom{|}n})x^n$ \retTwo\par}

   Hence, we have for each $n$ that $a_n = \alpha_1r_1^{\vphantom{|}n} + \alpha_2r_2^{\vphantom{|}n}$.
\end{myIndent}

\newpage

\mHeader{Lecture 2: 9/30/2024}

\begin{myIndent}\hTwo
   \blab{Approach 3: (Matrices)}\\
   If $a_n = c_1a_{n-1} + c_2a_{n-2}$, then we can say that: $\begin{bmatrix}c_1 & c_2 \\ 1 & 0\end{bmatrix}\begin{bmatrix}a_{n-1} \\ a_{n-2}\end{bmatrix} = \begin{bmatrix}a_n \\ a_{n-1}\end{bmatrix}$\retTwo

   Letting $\bm{C} = 
   \begin{bmatrix}
      c_1 & c_2 \\ 1 & 0
   \end{bmatrix}$, we thus know that: $\bm{C}^n \begin{bmatrix}a_1 \\ a_0\end{bmatrix} = \begin{bmatrix}a_{n+1} \\ a_{n}\end{bmatrix}$\retTwo

   Notably, the characteristic polynomial of $\bm{C}$ is $t^2 - c_1t - c_2$. So the eigenvalues of $\bm{C}$ are $r_1$ and $r_2$. Because we assumed $r_1$ and $r_2$ are distinct, we know $\bm{C}$  is\\ diagonalizable. Hence there exists an invertible matrix $\bm{B}$ such that:
   
   {\center$\bm{B}
   \begin{bmatrix}
      r_1 & 0 \\ 0 & r_2
   \end{bmatrix}\bm{B}^{-1} = \bm{C}$\retTwo\par}

   Now set $\begin{bmatrix} x \\ y\end{bmatrix} = \bm{B}^{-1}\begin{bmatrix} a_1 \\ a_0\end{bmatrix}$. Then we can see that:

   {\center $\begin{bmatrix}
      a_{n+1} \\ a_n
   \end{bmatrix} =
   \bm{C}^n\begin{bmatrix}
      a_1 \\ a_0
   \end{bmatrix} = \bm{B}\bm{D}^n\begin{bmatrix}
      x \\ y
   \end{bmatrix} = \bm{B}\begin{bmatrix}
      r_1^{\vphantom{|}n}x \\ r_2^{\vphantom{|}n}y
   \end{bmatrix} = \begin{bmatrix}
     b_{1,1} r_1^{\vphantom{|}n}x + b_{1,2}r_2^{\vphantom{|}n}y \\ b_{2,1} r_1^{\vphantom{|}n}x + b_{2,2}r_2^{\vphantom{|}n}y
   \end{bmatrix}$ \retTwo\par}

   Setting $\alpha_1 = b_{2,1}x$ and $\alpha_2 = b_{2,2}y$, we have thus found constants $\alpha_1$ and $\alpha_2$ such that $a_n = \alpha_1r_1^{\vphantom{|}n} + \alpha_2r_2^{\vphantom{|}n}$.\retTwo\retTwo
\end{myIndent}

\hOne
Now some further questions to ask about recurrence relations are:
\begin{enumerate}
   \item What if $r_1 = r_2$?
   \item What if $d \geq 3$?
   \item What if the recurrence relation is non-homogeneous or non-linear?\retTwo
\end{enumerate}

To start, let's answer question 1.
\begin{myIndent}\hTwo
   \blab{Theorem:} Suppose $r_1$ and $r_2$ are the roots of $t^2 - c_1t - c_2$ with $r_1 = r_2$. Then there exists $\alpha_1, \alpha_2$ such that $a_n = \alpha_1r_1^{\vphantom{|}n} + \alpha_2 n r_1^{\vphantom{|}n}$ for all $n \geq 0$.\retTwo

   As was true when $r_1 \neq r_2$, you can solve for $\alpha_1$ and $\alpha_2$ by plugging in different values of $n$ into the equation in order to get a linear system of equations.\retTwo
\end{myIndent}

To explain why this is, let's revisit two of our previous approaches.\retTwo

\begin{myIndent}\hTwo
   \blab{The Formal Power Series Approach Revisited:}\\
   Before, we were able to show that $A(x) = \dfrac{a_0 + (a_1 - a_0c_1)x}{(1 - r_1x)(1 - r_2x)}$ without assuming\\ [-7pt] anything about $r_1$ and $r_2$.\newpage

   But when we assume $r_1 = r_2$, we then get a different partial fraction decomposition for $A(x)$. Specifically, we have that there exists constants $\beta_1, \beta_2$ such that:

   {\centering $A(x) = \dfrac{\beta_1}{1 - r_1x} + \dfrac{\beta_2}{(1 - r_1x)^2} $ \retTwo\par}

   Now we'll go into more rigor later. But for now, note that:

   {\centering $\frac{1}{(1 - y)^2} = \frac{d}{dy}\left(\frac{1}{1 - y}\right) = \frac{d}{dy}\left(\sum\limits_{n\geq 0}y^n\right) = \sum\limits_{n \geq 1}ny^{n-1} = \sum\limits_{n \geq 0}(n+1)y^n$\par}

   
   \begin{myTindent}\myComment
      Comment from the future: this explanation actually is completely\\ incorrect because $x$ isn't a variable that we can plug in at all (we'll get to that in the next lecture). The professor just mentioned this explanation cause it's a cool connection.  \retTwo
   \end{myTindent}

   Hence, we can write $A(x) = \sum\limits_{n \geq 0}a_n x^n = (\beta_1 + \beta_2) \sum\limits_{n \geq 0}r_1^{\vphantom{|}n}x^n + \beta_2 \sum\limits_{n \geq 0}nr_1^{\vphantom{|}n}x^n$.\retTwo

   Or in other words, setting $\alpha_1 = \beta_1 + \beta_2$ and $\alpha_2 = \beta_2$, we have that:

   {\centering $a_n = \alpha_1r_1^{\vphantom{|}n} + \alpha_2 n r_1^{\vphantom{|}n}$\\ [20pt]\par}

   \blab{The Matrix Approach Revisited:}\\

   If $r_1 = r_2$, then we must hav ethat the matrix $\bm{C}$ is not diagonalizable. For suppose it was, meaning there exists an invertible matrix $\bm{B}$ such that:
   
   {\centering$\bm{C} = \bm{B}
   \begin{bmatrix}
      r_1 & 0\\ 0 & r_1
   \end{bmatrix}\bm{B}^{-1}$\retTwo\par}

   Then we'd have to have that $\bm{C} = r_1\bm{B}\bm{B}^{-1} = 
   \begin{bmatrix}
      r_1 & 0 \\ 0 & r_1
   \end{bmatrix}$. But we know $\bm{C}$ isn't that.\retTwo

   Since we know $\bm{C}$ Is not diagonalizable, we will instead use the \textit{Jordan-normal form} of $\bm{C}$. Specifically, we know there exists an invertible matrix $\bm{B}$ such that:

   {\centering $\bm{C} = \bm{B}
   \begin{bmatrix}
      r_1 & 1 \\ 0 & r_1
   \end{bmatrix}\bm{B}^{-1}$\par}
   
   \begin{myDindent}\begin{myDindent}\myComment
      Don't worry for the time being about how to prove the Jordan-normal form of a matrix always exists.\retTwo
   \end{myDindent}\end{myDindent}

   This tells us that $\bm{C}^n = 
   \bm{B}\begin{bmatrix}
      r_1 & 1 \\ 0 & r_1
   \end{bmatrix}^n\bm{B}^{-1}$.\retTwo Also, you can show by induction that $\begin{bmatrix}
      r_1 & 1 \\ 0 & r_1
   \end{bmatrix}^n = \begin{bmatrix}
      r_1^n & nr_1^{n-1} \\ 0 & r_1^n
   \end{bmatrix}$.

   So finally, defining $
   \begin{bmatrix}
      x \\ y
   \end{bmatrix}$ as before and expanding out the expression, you can get\\ [-8pt] \phantom{aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa} an explicit equation for $a_n$.\newpage
\end{myIndent}

As for answering question 2, if $d \geq 3$, then our characteristic polynomial becomes $t^d - c_1t^{d-1} - \ldots - c_d$. We'll assume this polynomial has distinct roots $r_1, \ldots, r_m$ with multiplicities $s_1, \ldots, s_m$ respectively.\retTwo


\begin{myIndent}\hTwo
   \blab{Theorem:} There exists constants $\alpha_1, \ldots, \alpha_d$ such that:

   {\center $a_n = \sum\limits_{i = 1}^{s_1} \alpha_i n^{\vphantom{|}i-1} r_1^{\vphantom{|}n} + \ldots + \hspace{-2em}\sum\limits_{i = s_1 + \ldots + s_{m-1} + 1}^{s_1 + \ldots + s_m}\hspace{-2em} \alpha_i n^{\vphantom{|}i-1}r_m^{\vphantom{|}n}$ \retTwo\par}

   As before, to solve for $\alpha_1$ through $\alpha_d$, you can plug in values of $n$ and solve a linear system of equations.\retTwo

   \begin{myIndent}\hThree
      The approaches to prove this are the same as when $d = 2$. However, there are just more terms floating around that need to be dealt with.\retTwo
   \end{myIndent}
\end{myIndent}

Special case: suppose the characteristic polynomial is $(t - 1)^d$.

\begin{myIndent}\hTwo
   In that case, because the root of the polynomial $r$ is $1$, there exists $\alpha_1, \ldots, \alpha_d$\\ such that 
   
   {\centering $a_n = \alpha_1 + n\alpha_2 + n^2\alpha_3 + \ldots + n^{d-1}\alpha_d$. \retTwo\par}
   
   In other words, the formula for $a_n$ is a polynomial in $n$.\retTwo
\end{myIndent}

\mySepTwo

\blab{Another perspective on the characteristic polynomial}:\\

Let $V$ be the vector space of sequences $(a_n)_{n\geq 0}$, and define the \udefine{translation operator} $T: V \longrightarrow V$ such that $(a_n)_{n \geq 0} \mapsto (a_{n+1})_{n\geq 0}$. Now, given $\bm{a} \in V$ and the recurrence relation $a_n = c_1a_{n-1} + \ldots + c_da_{n-d}$ for all $n \geq d$, we have that $\bm{a}$ satisfies our recurrence relation if and only if:

{\centering $T^d\bm{a} = c_1T^{d-1}\bm{a} + c_2T^{d-2}\bm{a} + \ldots + c_d\bm{A}$ \retTwo\par}

In other words, we must have that $\bm{a} \in \ker(T^d - c_1T^{d-1} - \ldots - c_d)$.\retTwo

If $r_1, \ldots, r_d$ are the roots of the characteristic polynomial $t^d - c_1T^{d-1} - \ldots - c_d$, then we can rewrite this as:

{\centering $(T - r_1)\cdots(T - r_d)\bm{a} = \bm{0}$ \retTwo\par}

\begin{myIndent}\hTwo
   \blab{Proposition:} Given a sequence $\bm{a} = (a_n)_{n \geq 0}$, there exists a polynomial $p(n)$ of\\ degree at most $d - 1$ such that $a_n = p(n)$ if and only if $(T - 1)^d\bm{a} = \bm{0}$.

   \begin{myIndent}\hThree
      We already saw in the special case above one direction of this statement. As for the other direction, suppose $p(n) = \alpha_d n^{d-1} + \alpha_{d-1}n^{d-2} + \ldots + \alpha_1$. Then $(T - 1)$ applied to the sequence $(p(n))_{n\geq 0}$ is the sequence $(p(n + 1) - p(n))_{n \geq 0}$ Importantly, $p(n + 1)$ is also a polynomial of degree $d - 1$ with $\alpha_d$ as the coefficient in front of $n^{d - 1}$. So the difference is a polynomial of degree at most $d - 2$.\newpage

      Proceeding by induction, we know that $(T - 1)^d(p(n))_{n\geq 0} = \bm{0}$.\retTwo
   \end{myIndent}   
\end{myIndent}

Note that the operator $(T - 1)$ can be thought of as the taking the "derivative" of a sequence $\bm{a}$. Going by that analogy, the previous proposition is saying that a sequence $\bm{a}$ is given by a polynomial if and only if a derivative of some order of the sequence is zero. Interestingly, the same is true of differential equations.\retTwo

\mySepTwo

\mHeader{Lecture 3: 10/2/2024}











% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\newpage

\mHeader{Homework 1:}

(1) Find a closed formula for the following recurrence relation:

{\centering 
$\begin{matrix}
   a_0 = 1,\myHS a_1 = 0,\myHS a_2 = 2,\\
   a_n = 5a_{n-1} - 8a_{n-2} + 4a_{n-3} & \text{for } n \geq 3
\end{matrix}$ \retTwo\par}



\end{document}