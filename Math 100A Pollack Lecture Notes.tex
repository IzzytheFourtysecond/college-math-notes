\documentclass{book}

\usepackage{fontspec} % used to import Calibri
\usepackage{anyfontsize} % used to adjust font size

% needed for inch and other length measurements
% to be recognized
\usepackage{calc}

% for colors and text effects as is hopefully obvious
\usepackage[dvipsnames]{xcolor}
\usepackage{soul}

% control over margins
\usepackage[margin=1in]{geometry}
\usepackage[strict]{changepage}

\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{bm}

\usepackage[scr=rsfso, scrscaled=.96]{mathalpha}

\usepackage{amssymb} % originally imported to get the proof square
\usepackage{xfrac}
\usepackage[overcommands]{overarrows} % Get my preferred vector arrows...
\usepackage{relsize}

% Just am using this to get a dashed line in a table...
% Also you apparently want this to be inactive if you aren't
% using it because it slows compilation.
\usepackage{arydshln} \ADLinactivate 
\newenvironment{allowTableDashes}{\ADLactivate}{\ADLinactivate}

\usepackage{graphicx}
\graphicspath{{./158_Images/}}

\usepackage{tikz}
   \usetikzlibrary{arrows.meta}
   \usetikzlibrary{graphs, graphs.standard}

\usepackage{quiver} %commutative diagrams


\newfontfamily{\calibri}{Calibri}
\setlength{\parindent}{0pt}
\definecolor{RawerSienna}{HTML}{945D27}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%Arrow Commands:

% Thank you Bernard, gernot, and Sigur who I copied this from:
% https://tex.stackexchange.com/questions/364096/command-for-longhookrightarrow
\newcommand{\hooklongrightarrow}{\lhook\joinrel\longrightarrow}
\newcommand{\hooklongleftarrow}{\longleftarrow\joinrel\rhook}
\newcommand{\hookxlongrightarrow}[2][]{\lhook\joinrel\xrightarrow[#1]{#2}}
\newcommand{\hookxlongleftarrow}[2][]{\xleftarrow[#1]{#2}\joinrel\rhook}

% Thank you egreg who I copied from:
% https://tex.stackexchange.com/questions/260554/two-headed-version-of-xrightarrow
\newcommand{\longrightarrowdbl}{\longrightarrow\mathrel{\mkern-14mu}\rightarrow}
\newcommand{\longleftarrowdbl}{\leftarrow\mathrel{\mkern-14mu}\longleftarrow}

\newcommand{\xrightarrowdbl}[2][]{%
  \xrightarrow[#1]{#2}\mathrel{\mkern-14mu}\rightarrow
}
\newcommand{\xleftarrowdbl}[2][]{%
  \leftarrow\mathrel{\mkern-14mu}\xleftarrow[#1]{#2}
}

\newcommand{\MRoman}[1]{%
   \textrm{\MakeUppercase{\romannumeral #1}}%
}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\newcommand{\learnToSpot}[1]{{\color{Red}#1}}

\newcommand{\hOne}{%
   \color{Black}%
   \fontsize{14}{16}\selectfont%
}
\newcommand{\hTwo}{%
\color{MidnightBlue}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\hThree}{%
   \color{PineGreen!85!Orange}
   \fontsize{12}{14}\selectfont%
}
\newcommand{\hFour}{%
   \color{Cyan!80!black}
   \fontsize{12}{14}\selectfont%
}
\newcommand{\myComment}{%
   \color{RawerSienna}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\teachComment}{
   \color{Orange}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\exOne}{%
   \color{Purple}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\exTwo}{%
   \color{Purple}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\exP}{%
   \color{Purple}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\exTwoP}{%
   \color{RedViolet}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\exPP}{%
   \color{RedViolet}%
   \fontsize{12}{14}\selectfont%
}
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\newcommand{\cyPen}[1]{{\vphantom{.}\color{Cerulean}#1}}
\newcommand{\redPen}[1]{{\vphantom{.}\color{Red}#1}}

\newenvironment{myIndent}{%
   \begin{adjustwidth}{2.5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myDindent}{%
   \begin{adjustwidth}{5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myTindent}{%
   \begin{adjustwidth}{7.5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myConstrict}{%
   \begin{adjustwidth}{2.5em}{2.5em}%
}{%
   \end{adjustwidth}%
}

\newcommand{\udefine}[1]{{%
   \setulcolor{Red}%
   \setul{0.14em}{0.07em}%
   \ul{#1}%
}}

\newcommand{\blab}[1]{\textbf{#1}}

\newcommand{\uuline}[2][.]{%
{\vphantom{a}\color{#1}%
\rlap{\rule[-0.18em]{\widthof{#2}}{0.06em}}%
\rlap{\rule[-0.32em]{\widthof{#2}}{0.06em}}}%
#2}

\newcommand{\pprime}{{\prime\prime}}
\newcommand{\suchthat}{ \hspace{0.3em}s.t.\hspace{0.3em}}
\newcommand{\comp}{\mathsf{C}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\Sym}{\mathrm{Sym}}
\newcommand{\myHS}{ \hspace{0.5em}}

\newcommand{\myId}{\mathrm{Id}}
\newcommand{\myObj}{\mathrm{Obj}}
\newcommand{\myHom}{\mathrm{Hom}}
\newcommand{\myEnd}{\mathrm{End}}
\newcommand{\myAut}{\mathrm{Aut}}
\newcommand{\mMod}[1]{\phantom{a}(\mathrel{\mathrm{mod}} #1)}

\newcommand{\mcateg}[1]{{\bm{\mathsf{#1}}}}

\newcommand{\divides}{\mathop{\mid}}

\newcommand{\iso}{\cong}


\DeclareMathOperator{\ima}{Im}
\DeclareMathOperator{\rea}{Re}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\tr}{tr}

% Thank you Gonzalo Medina and Moriambar who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/74125/how-do-i-put-text-over-symbols%
\newcommand{\myequiv}[1]{\stackrel{\mathclap{\mbox{\footnotesize{$#1$}}}}{\equiv}}

% Thank you chs who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/89821/how-to-draw-a-solid-colored-circle%
\newcommand{\filledcirc}[1][.]{\ensuremath{\hspace{0.05em}{\color{#1}\bullet}\mathllap{\circ}\hspace{0.05em}}}

%Thank you blerbl who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/25348/latex-symbol-for-does-not-divide
\newcommand{\ndiv}{\hspace{-0.3em}\not|\hspace{0.35em}}

\newcommand{\mySepOne}[1][.]{%
   {\noindent\color{#1}{\rule{6.5in}{1mm}}}\\%
}
\newcommand{\mySepTwo}[1][.]{%
   {\noindent\color{#1}{\rule{6.5in}{0.5mm}}}\\%
}

\newenvironment{myClosureOne}[2][.]{%
   \color{#1}%
   \begin{tabular}{|p{#2in}|} \hline \\%
}{%
   \\ \hline \end{tabular}%
}

\newcommand{\retTwo}{\hfill\bigbreak}

\newcommand{\mHeader}[1]{{
   \color{Black}%
   \fontsize{20}{18}\selectfont%
   #1\retTwo
}}


\title{Math 100A Notes (Professor: Aaron Pollack)}
\author{Isabelle Mills}

\begin{document}
\maketitle{}
\setul{0.14em}{0.07em}
\calibri

\hOne
\mHeader{Lecture 1 Notes: 9/27/2024}

\blab{Motivation for this class:}

Let $\mathcal{F}$ be any figure in $\mathbb{R}^2$. We want some way of talking about the symmetries of $\mathcal{F}$.\retTwo

Letting $d$ be the standard metric for $\mathbb{R}^2$, we say $f: \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ is \udefine{distance preserving}\\ if $d(P, Q) = d(f(P), f(Q))$ for all $P, Q \in \mathbb{R}^2$. If $f$ is distance-preserving and\\ $f(\mathcal{F}) = \mathcal{F}$, then we call $f$ a \udefine{symmetry} of $\mathcal{F}$.\retTwo

We define $\Sym(\mathcal{F})$ to be the set of symmetries of $\mathcal{F}$.
\begin{myIndent}\hTwo
	Lemma 2: The set $\Sym(\mathcal{F})$ has the following properties:
	
	\begin{enumerate}
		\item The identity map $\myId$ is in $\Sym(\mathcal{F})$
		\item If $f \in \Sym(\mathcal{F})$, then $f^{-1} \in \Sym(\mathcal{F})$.
		\begin{myIndent}\hThree
			I realize we haven't yet shown that every $f \in \Sym(\mathcal{F})$ is a bijection. Given such an $f$, it's easy to see that $f$ must be injective. After all, the distance\\ preserving property of $f$ means that $f(P) = f(Q) \Longrightarrow P = Q$. Showing that $f$ is surjective is harder. By assumption, we know that $f$ is surjective when restricted to $\mathcal{F}$. More complicatedly, we can show that $f$ must have a certain form which happens to be surjective. Perhaps I'll prove that later.\retTwo

			Once, you've accepted that $f^{-1}$ exists, then it's clearly true that $f^{-1}$ is also distance preserving with $f^{-1}(\mathcal{F}) = \mathcal{F}$.
		\end{myIndent}
		\item If $f_1, f_2 \in \Sym(\mathcal{F})$, then $f_1 \circ f_2 \in \Sym(\mathcal{F})$ and $f_2 \circ f_1 \in \Sym(\mathcal{F})$.
		\begin{myIndent}\hThree
			This is pretty trivial to show.\retTwo
		\end{myIndent}
	\end{enumerate}
\end{myIndent}

Now while it's all good that we have a concrete way of describing the symmetries of a figure, our current terminology is not the most useful. After all, suppose $\mathcal{S}$ and $\mathcal{S}^\prime$ are two squares such that $\mathcal{S}$ is centered at the origin and $\mathcal{S}^\prime$ is centered at the point $(5, 5)$. Then even though we know both $\mathcal{S}$ and $\mathcal{S}^\prime$ have symmetries in the form of rotating and reflecting, the particular functions in $\Sym(\mathcal{S})$ and $\Sym(\mathcal{S})$ will be different (except for $\myId$). So, how do we compare the symmetries of those two squares?\retTwo

\mySepTwo

Aside start\dots\retTwo

\blab{Proof that all symmetries are surjective (taken from our textbook)}:\\
\begin{myIndent}\myComment
	Note:\\ [-18pt]
	\begin{itemize}
		\item Our textbook calls a distance-preserving function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ an \udefine{isometry}.
		\item Rather than writing $f_1 \circ f_2$ to represent function composition, our textbook just\\ writes $f_1f_2$.\newpage
	\end{itemize}

	\hTwo
	\blab{Some Facts:}
	\begin{itemize}
		\item[(a)] Orthogonal linear operators are isometries.
		
		\begin{myIndent}\hThree
			Let $\varphi$ be n orthogonal linear map. $\varphi$ being linear means that\\ $\varphi(u) - \varphi(v) = \varphi(u - v)$. Meanwhile, $\varphi$ being orthogonal means that\\ $|\varphi(u - v)| = \sqrt{\varphi(u - v) \cdot \varphi(u -v)} = \sqrt{(u - v) \cdot (u - v)} = |u - v|$.\\ So, for any $u, v \in \mathbb{R}^n$, we have that $|\varphi(u) - \varphi(v)| = |u - v|$.\retTwo
		\end{myIndent}

		\item[(b)] The translation $t_a$ by a vector $a$ defined by $t_a(x) = x + a$ is an isometry.
		\begin{myIndent}\hThree
			For any $u, v \in \mathbb{R}^n$, we have $|t_a(u) - t_a(v)| = |u + a - v - a| = |u - v|$.\retTwo
		\end{myIndent}

		\item[(c)] The composition of isometries is an isometry.
		\begin{myIndent}\hThree
			If $f_1, f_2$ are isometries, then for all $u, v \in \mathbb{R}^n$, we have that\\ $|f_1(f_2(u)) - f_1(f_2(v))| = |f_2(u) - f_2(v)| = |u - v|$.\retTwo
		\end{myIndent}
	\end{itemize}

	\blab{Theorem 6.2.3:} The following conditions on a map $\varphi: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ are equivalent:
	\begin{itemize}
		\item[(a)] $\varphi$ is an isometry such that $\varphi(0) = 0$.
		\item[(b)] $\varphi$ preserves dot products: $\varphi(u) \cdot \varphi(w) = u \cdot w$ for all $u, w \in \mathbb{R}^n$.
		\item[(c)] $\varphi$ is an orthogonal linear operator.
		
		\begin{myIndent}\hThree
			Proof:\\
			(c) $\Longrightarrow$ (a)\\
			This comes both from the first fact on this page plus the fact that all linear\\ operators map $0$ to $0$.\retTwo

			(b) $\Longrightarrow$ (c)\\
			Our challenge here is to show that such a $\varphi$ has to be linear operator.\retTwo

			\blab{Lemma:} For $x, y \in \mathbb{R}^n$, if $(x \cdot x) = (x \cdot y) = (y \cdot y)$, then $x = y$.
			
			\begin{myIndent}\hThree
				Proof: $|x - y|^2 = (x - y) \cdot (x - y) = (x \cdot x) - 2(x \cdot y) + (y \cdot y)$.\retTwo
			\end{myIndent}

			Consider any $u, v \in \mathbb{R}^n$ and set $w = u + v$. Then set $u^\prime = \varphi(u)$,\\ $v^\prime = \varphi(v)$, and $w^\prime = \varphi(w)$. To show that $w^\prime = v^\prime + u^\prime$, we shall show\\ that $(w^\prime \cdot w^\prime) = (w^\prime \cdot (u^\prime + v^\prime)) = ((u^\prime + v^\prime) \cdot (u^\prime + v^\prime))$.\retTwo

			Firstly, simplify our equation to:

			{\centering $(w^\prime \cdot w^\prime) = (w^\prime \cdot u^\prime) + (w^\prime \cdot v^\prime) = (u^\prime \cdot u^\prime) + 2(u^\prime \cdot v^\prime) + (v^\prime \cdot v^\prime)$ \retTwo\par}

			Next, since $\varphi$ is assumed to preserve dot products, we can thus simplify our\\ equation to:

			{\centering $(w \cdot w) = (w \cdot u) + (w \cdot v) = (u \cdot u) + 2(u\cdot v) + (v \cdot v)$ \retTwo\par}

			And since $w = u + b$, all of those equalities are true. Hence, we know by our lemma above that $w^\prime = u^\prime + v^\prime$.\newpage

			Meanwhile, let $v \in \mathbb{R}^n$ and set $u = cv$ where $c$ is a constant. Then define $u^\prime$ and $v^\prime$ as before. Then we can do a few trivial simplications to show that $(u^\prime \cdot u^\prime)$, $(u^\prime \cdot cv^\prime)$ and $(cv^\prime \cdot cv^\prime)$ are all equal to $c^2(v \cdot v)$. So, $u^\prime = cv^\prime$.\retTwo

			(a) $\Longrightarrow$ (b)\\
			Since $\varphi$ is distance preserving, we know that $\forall u, v \in \mathbb{R}^n$, 

			{\centering$(\varphi(u) - \varphi(v)) \cdot (\varphi(u) - \varphi(v)) = (u - v) \cdot (u -v)|$.\retTwo\par}

			By plugging in $v = 0$, this simplifies to $(\varphi(u) \cdot \varphi(u)) = (u \cdot u)$. Similarly, by plugging in $u = 0$, we can get that $(\varphi(v) \cdot \varphi(v)) = (v \cdot v)$. So, by expanding and canceling out parts of our above expression, we get that:

			{\centering$-2(\varphi(u) \cdot \varphi(v)) = - 2(u \cdot v)$.\retTwo\par}
		\end{myIndent}
	\end{itemize}

	\blab{Corollary 6.2.7:} Every isometry $f$ of $\mathbb{R}^n$ is the composition of an orthogonal linear operator and a translation. Specifically, if $f(0) = a$, then $f = t_a\varphi$ where $t_a$ is a translation and $\varphi$ is an orthogonal linear operator.

	\begin{myIndent}\hThree
		Proof:\\
		Let $f$ be an isometry, let $a = f(0)$, and define $\varphi = t_{-a}f$. Then clearly $t_a\varphi = f$. So, we just need to show that $\varphi$ is an orthogonal linear operator. To prove this, first note that $\varphi$ is the composition of two isometries, and is thus an isometry itself. Also, $\varphi(0) = -a + f(0) = -a + a = 0$. So applying theorem 6.2.3, we know that $\varphi$ is an orthogonal linear operator.\retTwo
	\end{myIndent}
\end{myIndent}

Now we've proven in other classes that both translations and linear orthogonal\\ operators on $\mathbb{R}^n$ are surjective. So, all isometries are the composition of surjections, meaning they are surjective themselves. And since we also previously proved that all isometries are injective, we know they are bijective and have inverses.\retTwo

Aside over\dots

\mySepTwo

\mHeader{Lecture 2 Notes: 9/30/2024}

I already covered everything from this lecture in my math journal (pages 40-42).\\

\mySepTwo

\mHeader{Lecture 3 Notes: 10/2/2024}

Suppose $G_1$ and $G_2$ are groups. A map $\rho: G_1 \longrightarrow G_2$ is called a \udefine{group\\ homomorphism} if $\rho(xy) = \rho(x)\rho(y)$ for all $x, y \in G_1$. If $\rho$ is bijective, we say that\\ $\rho$ is an \udefine{isomorphism}, and that $G_1$ and $G_2$ are \udefine{isormophic.} Also if $\rho$ is bijective, we\\ have that $\rho^{-1}$ is also a group homomorphism.\newpage

If two groups are isomorphic, then we can say they are in a sense equivalent.\retTwo

Suppose $G$ is a group and $H \subseteq G$. Then $H$ equipped with the law of composition of $G$ restricted to $H \times H$ is a \udefine{subgroup} if:\\ [-20pt]
\begin{itemize}
	\item $1 \in H$\\ [-20pt]
	\item $x \in H \Longrightarrow x^{-1} \in H$\\ [-20pt]
	\item $x, y \in H \Longrightarrow xy \in H$\retTwo
\end{itemize}

\exOne

Example: If $\mathbb{R}^\times = (\mathbb{R} - \{0\}, \times)$, then some non-trivial subgroups of $\mathbb{R}^x$ are:\\ [-20pt]

\begin{itemize}
	\item $M_2 = \{1, -1\}$\\ [-20pt]
	\item $\mathbb{Z}^x = \mathbb{Z} - \{0\}$\\ [-20pt]
	\item $\mathbb{Q}^x = \mathbb{Q} - \{0\}$\\ [-20pt]
	\item $H = \{a^n \in \mathbb{R} \mid n \in \mathbb{Z}\}$.
\end{itemize}

\begin{myIndent}\hTwo
	\blab{Theorem:} Let $S$ be a subgroup of $(\mathbb{Z}, +)$ (the set of integers equipped with integer addition). Then either $S = \{0\}$ or $S = \mathbb{Z}a = \{na \mid n \in \mathbb{Z}\}$ where $a$ is the least positive element of $S$.

	
	\begin{myIndent}\hThree
		Proof:\\
		We clearly have that $\{0\}$ and $\mathbb{Z}a$ are groups under addition for any $a \in \mathbb{Z}_+$.\\ Meanwhile, suppose $S \neq \{0\}$ is a subgroup of $(\mathbb{Z}, +)$. Then, by taking inverses if necessary, we know $S \cap \mathbb{Z}_+$ is nonempty. Since $\mathbb{Z}_+$ is well-ordered, there exists a least element in $S \cap \mathbb{Z}_+$ which we'll call $a$.\retTwo

		Trivially, we have that $\mathbb{Z}a \subseteq S$. Meanwhile consider any $n \in S$. Then $n = qa + r$ for some $q \in \mathbb{Z}$ and $r \in \{0, 1, \ldots, a - 1\}$. However, since $r = n - qa$ and $n, -qa \in S$, we must have that $r \in S$. And, the only allowed value for $r$ such that $r \in S$ is $r = 0$. Thus, $n \in \mathbb{Z}a$, meaning we've shown that $S \subseteq \mathbb{Z}_a$.\retTwo
	\end{myIndent}
\end{myIndent}

\hOne\mySepTwo

\mHeader{Lecture 4 Notes: 10/4/2024}

As an immediate application of the above theorem, note that $S = \mathbb{Z}a + \mathbb{Z}b = \{ma + nb \mid m, n \in \mathbb{Z}\}$ is subgroup of $\mathbb{Z}$ under addition.
\begin{myTindent}\myComment
	This is trivial to prove.\retTwo
\end{myTindent}

By our previous theorem, we know that $S = \mathbb{Z}d$ for some unique positive integer $d$. So, we define the \udefine{greatest common divisor} of $a$ and $b$ to be $\gcd(a, b) \coloneq d$.

\begin{myIndent}\hTwo
	\blab{Proposition:} Let $a, b \in \mathbb{Z}$ be not both $0$ and $d = \gcd(a, b)$.
	\begin{enumerate}
		\item There exists $r, s \in \mathbb{Z}$ such that $d = ra + sb$
		\item $d$ divides $a$ and $b$ (written $d \divides a$ and $d \divides b$).
		\begin{myIndent}\hThree
			Both of these claims are trivially true by our definition of $S$.\newpage
		\end{myIndent}
		\item If $e \in \mathbb{Z}$ and $e$ divides $a$ and $b$, then $e$ divides $d$. This is why $d$ is called the\\ "greatest common divisor" of $a$ and $b$.
		\begin{myIndent}\hThree
			Let $r, s \in \mathbb{Z}$ such that $d = ra + sb$. Then letting $a = en$ and $b = em$, we have that $d = (rn + sm)e$, meaning $e \divides d$.\retTwo
		\end{myIndent}
	\end{enumerate}
\end{myIndent}

An algorithm for finding $\gcd(a, b)$ is given as follows:
\begin{enumerate}
	\item Assume without loss of generality that $a \geq b \geq 0$ and $a \neq 0$.
	\item If $b = 0$, then $\gcd(a, b) = \gcd(b, a) = a$
	\item Else, there exists $q, r \in \mathbb{Z}$ with $0 \leq r < b$ and $a = qb + r$. We claim\\ that $\gcd(a, b) = \gcd(b, r)$.
	
	\begin{myIndent}\hTwo
		This is because if $d \divides a$ and $d \divides b$, then we know $d \divides (qb + r)$ and $d \divides qb$,\\ meaning that $d \divides (qb + r - qb) = r$. On the other hand, if $e \divides r$ and $e \divides b$,\\ then $e \divides (qb + r) = a$. So $a$ and $b$ have the same common factors as $b$ and $c$.\retTwo
	\end{myIndent}
\end{enumerate}

Suppose $a, b \in \mathbb{Z}$. We say $a$ and $b$ are \udefine{relatively prime} iff $\gcd(a, b) = 1$.

\begin{myIndent}\hTwo
	\blab{Corollary:} $\gcd(a, b) = 1$ if and only if there exists $r, s \in \mathbb{Z}$ such that $ra + sb = 1$.
	\begin{myIndent}\hThree
		Proof:\\
		($\Longrightarrow$) By definition, $\gcd(a, b) \in \mathbb{Z}a + \mathbb{Z}b$.\\
		($\Longleftarrow$) If $ra + sb = 1$, then $1$ must be the least positive element of $\mathbb{Z}a + \mathbb{Z}b$.\\ So $\gcd(a, b) = 1$.\retTwo
	\end{myIndent}

	\blab{Lemma:} Suppose $\gcd(a, b) = 1$ and $a \divides bc$. Then $a \divides c$.
	\begin{myIndent}\hThree
		Proof:\\
		Let $1 = ra + sb$ where $r, s \in \mathbb{Z}$. Then $c = rac + sbc = (rc + s\frac{bc}{a})a$ where $\frac{bc}{a}$\\ [-2pt] is an integer. So $a \divides c$.\retTwo
	\end{myIndent}

	\blab{Corollary:} Suppose $p$ is a prime integer. If $a, b \in \mathbb{Z}$ and $p \divides ab$, then either $p \divides a$\\ or $p \divides b$.
	\begin{myIndent}\hThree
		Proof:\\
		Suppose $p {\not\divides a}$. Then $\gcd(p, a) = 1$ because the only positive divisor of $p$ other\\ than $p$ is $1$. So there exists $r, s \in \mathbb{Z}$ such that $1 = rp + sa$. In turn, since $\frac{ab}{p}$ is an\\ [-3pt] integer, we have $b = rpb + sab = p(rb +s\frac{ab}{p})$, meaning $p \divides b$.\retTwo
	\end{myIndent}
\end{myIndent}

\exOne\mySepTwo

\blab{Problem:} Suppose $p$ is prime and that $a \in \mathbb{Z}$ is not a multiple of $p$. Then there exists $x \in \mathbb{Z}$ so that $ax$ is one more than some multiple of $p$.

\begin{myIndent}\exTwoP
	Proof:\\
	Like before, we must have that $\gcd(a, p) = 1$, meaning that there exists $r, s \in \mathbb{Z}$\\ such that $rp + sa = 1$. So, if we set $x = s$, we'd be done cause $xa = (-r)p + 1$.\retTwo

	More interestingly, we can guarentee that $xa$ is one more than a nonnegative multiple of $p$ as follows:\newpage
	\begin{myIndent}
		Note that $sa = -rp + 1 \Longrightarrow (s^2a)a = (r^2p - 2r)p + 1 = r(rp - 2)p + 1$.\\ Since $p \geq 2$, we have that $r \geq 1 \Longrightarrow (rp - 2) > 0$, meaning $r(rp - 2) > 0$.\\ Meanwhile, we have that $r \leq 0 \Longrightarrow (rp - 2) < 0$, which in turn means $r(rp - 2) \geq 0$.\retTwo

		Setting $x = s^2a$ and $n = r^2p - 2r$, we thus have that $xa = np + 1$ where\\ $np$ is a nonnegative multiple of $p$.
	\end{myIndent}
\end{myIndent}

\mySepTwo

\hTwo
\blab{Lemma:} Suppose $G$ is a group and $\{H_\alpha\}_{\alpha \in A}$ are subgroups of $G$. Then $\hspace{-0.3em}\bigcap\limits_{\alpha \in A}\hspace{-0.3em}H_\alpha$ is a\\ [-10pt] subgroup of $G$.
\begin{myIndent}\hThree
	This is rather trivial to prove. So do it yourself! :3\retTwo
\end{myIndent}

\hOne

Because of the above lemma, given $a, b \in \mathbb{Z}$, we have that $\mathbb{Z}a \cap \mathbb{Z}b = \mathbb{Z}m$ for some integer $m \geq 0$. We call $m$ the \udefine{least common multiple} of $a$ and $b$, and we denote $\lcm(a, b) \coloneq m$.

\begin{myIndent}\hTwo
	\blab{Proposition:} Let $a$ and $b$ be nonzero integers and $m = \lcm(a, b)$.
	\begin{enumerate}
		\item $m$ is nonzero.
		\item $m$ is divisible by both $a$ and $b$
		\begin{myIndent}\hThree
			Both of these points are trivial from the fact that $\mathbb{Z}a \cap \mathbb{Z}b = \mathbb{Z}m$ and\\ $ab \in \mathbb{Z}m$, meaning that $\mathbb{Z}m - \{0\} \neq \emptyset$.
		\end{myIndent}
		\item If $n \in \mathbb{Z}$ such that $a \divides n$ and $b \divides n$, then $m \divides n$.
		\begin{myIndent}\hThree
			This comes trivially from the fact that $n \in \mathbb{Z}a$ and $n \in \mathbb{Z}b$ means that\\ $n \in \mathbb{Z}a \cap \mathbb{Z}b = \mathbb{Z}m$\retTwo
		\end{myIndent}
	\end{enumerate}
\end{myIndent}


Suppose $G$ is a group and $x \in G$. Then let $H = \{x^k \mid k \in \mathbb{Z}\} \subseteq G$. We clearly have that $H$ is a subgroup of $G$. We call it the \udefine{cyclic subgroup} of $G$ generated by $x$, and denote it $H = \langle x \rangle$.

\begin{myIndent}\hTwo
	\blab{Proposition:} Let $S = \{k \in \mathbb{Z} \mid x^k = 1\}$
	\begin{enumerate}
		\item $S$ is a subgroup of $(\mathbb{Z}, +)$.
		\begin{myIndent}\hThree
			This is rather trivial to show. So do it yourself!!
		\end{myIndent}
		\item Suppose $S \neq \{0\}$, meaning $S = \mathbb{Z}n$ for some positive integer $n$. Then\\ $1, x, \ldots, x^{n-1}$ are the distinct elements of $\langle x \rangle$, meaning the order of $\langle x \rangle$ is $n$.
		
		\begin{myIndent}\hThree
			Proof:\\
			$x^{k} = x^{l} \Longleftrightarrow x^{k-l} = 1$. Hence, since $n$ is the minimum positive integer such that $x^n = 1$, we know that $1, x, \ldots, x^{n-1}$ are distinct. On the other hand, if $k = qn + r$ for any $q, r \in \mathbb{Z}$ with $0 \leq r < n$, then $x^k = (x^n)^qx^r = x^r$. So the only elements of $\langle x \rangle$ are $1, x, \ldots, x^{n-1}$.\retTwo
		\end{myIndent}
	\end{enumerate}
\end{myIndent}

\newpage

\begin{myIndent}\hTwo
	\blab{Corollary}: If $S = \{k \in \mathbb{Z} \mid x^k = 1\} = \{0\}$, then $x^{k} = x^{l} \Longrightarrow k-l = 0 \Longrightarrow k = l$.\retTwo 
\end{myIndent}

\mHeader{Lecture 5 Notes: 10/7/2024}

If $G$ is a group and $x \in G$, one says $x$ has order $n$ if $n$ is the smallest positive integer for which $x^n = 1$. If there is no such integer, then we say $x$ has infinite order.\retTwo


\begin{myIndent}\hTwo
	\blab{Lemma:} Suppose that $G$ is a group, that $x \in G$ has order $n$, and that $\gcd(k , n) = d$. Then $x^k$ has order $\sfrac{n}{d}$.

	\begin{myIndent}\hThree
		Proof:\\
		Let $r = \ord(x^k)$. Then $x^{kr} = 1$, meaning $n \divides kr$. Since $d$ divides both $n$ and $k$, we thus have that $\frac{n}{d} \divides \frac{k}{d} r$. But $\gcd(\frac{n}{d}, \frac{k}{d}) = 1$ since $\gcd(n , k) = d$. So, we must have that $\frac{n}{d} \divides r$. Conversely, $(x^k)^{\sfrac{n}{d}} = (x^n)^{\frac{k}{d}} = 1$. So $r \divides \frac{n}{d}$. This means that $r = \frac{n}{d}$\retTwo
	\end{myIndent}
\end{myIndent}

If $G$ is a group and $U \subseteq G$, one can form the subgroup $H = \langle U\rangle$ of $G$ generated by $U$, meaning that $H$ is the intersection of all subgroups of $G$ containing $U$.\retTwo

\exOne\blab{Some Example Groups:}

\begin{itemize}
	\item The \udefine{Klein-4 Group} consists of the matrices with the form: $
	\left[\begin{smallmatrix}
		\pm 1 & 0 \\ 0 & \pm 1
	\end{smallmatrix}\right]$ or $
	\left[\begin{smallmatrix}
		\pm 1 & 0 \\ 0 & \mp 1
	\end{smallmatrix}\right]$.\\ [-16pt]

	It has four elements and is not cyclic.\retTwo

	\item The \udefine{Quaternion Group} consists of the 8 elements in $\mathrm{GL}_2(\mathbb{C})$: $\pm \bm{1} = \left[\begin{smallmatrix}
		 1 & 0 \\ 0 & 1
	\end{smallmatrix}\right]$,\\ $\pm \bm{I} = 
	\left[\begin{smallmatrix}
		i & 0 \\ 0 & -i
	\end{smallmatrix}\right]$, $\pm \bm{J} = 
	\left[\begin{smallmatrix}
		0 & 1 \\ -1 & 0
	\end{smallmatrix}\right]$, and $\pm \bm{K} = 
	\left[\begin{smallmatrix}
		 i & 0 \\ 0 & i
	\end{smallmatrix}\right]$.
\end{itemize}

\hOne

\mySepTwo

\begin{myIndent}\hTwo
	\blab{Proposition}: Suppose $\varphi: G \longrightarrow G^\prime$ is a group homomorphism. Then:
	\begin{enumerate}
		\item If $a_1, \cdots, a_k \in G_1$, then $\varphi(a_1\cdots a_k)=\varphi(a_1)\cdots\varphi(a_2)$.
		\item $\varphi(1_G) = 1_{G^\prime}$
		\item $\varphi(a^{-1}) = \varphi(a)^{-1}$
		
		\begin{myIndent}\hThree
			Proof:\\
			(1) This is true by induction. For example:
			
			{\centering $\varphi(a_1a_2a_3) = \varphi(a_1a_2)\varphi(a_3) = \varphi(a_1)\varphi(a_2)\varphi(a_3)$.\retTwo\par}

			(2) $\varphi(1_G) = \varphi(1_{G}1_{G}) = \varphi(1_G)\varphi(1_G)$. By multiplying $\varphi(1_G)^{-1}$ to both\\ sides, we  get that $\varphi(1_G) = 1_{G^\prime}$.\retTwo

			(3) $1_{G^\prime} = \varphi(1_G) = \varphi(aa^{-1}) = \varphi(a)\varphi(a^{-1})$. By multiplying $\varphi(a)^{-1}$ to both\\ sides, we get that $\varphi(a)^{-1} = \varphi(a^{-1})$.\newpage
		\end{myIndent}
	\end{enumerate}
\end{myIndent}

Suppose $\varphi: G \longrightarrow G^\prime$ is a group homomorphism. 
\begin{itemize}
	\item The \udefine{image} of $\varphi$ is: $\im(\varphi) = \varphi(G) = \{x \in G^\prime \mid x = \varphi(a) \text{ for some } a \in G\}$.
	\item The \udefine{kernel} of $\varphi$ is $\ker(\varphi) = \{x \in G \mid \varphi(x) = 1_{G^\prime}\}$.\retTwo
\end{itemize}


\begin{myIndent}\hTwo
	\blab{Proposition:} Let $\varphi: G \longrightarrow G^\prime$ be a group homomorphism. Then $\ker(\varphi) \subseteq G$ is a subgroup and $\im(\varphi)$ is a subgroup.
	
	\begin{myIndent}\hThree
		The kernel is a subgroup because if $\varphi(a) = 1_{G^\prime} = \varphi(b)$, then $\varphi(ab) = 1_{G^\prime}$. Also, if\\ $\varphi(a) = 1_{G^\prime}$, then $\varphi(a^{-1}) = \varphi(a)^{-1} = 1_{G^\prime}$. And finally, $\varphi(1_G) = 1_{G^\prime}$ as we showed earlier.\retTwo

		The image is subgroup because if $a^\prime, b^\prime \in \im(\varphi)$, then there exists $a, b \in G$ with $\varphi(a) = a^\prime$ and $\varphi(b) = b^\prime$. Then $\varphi(ab) = a^\prime b^\prime$, meaning $a^\prime b^\prime \in \im(\varphi)$. Also,\\ $\varphi(a^{-1}) = (a^\prime)^{-1}$, meaning $(a^\prime)^{-1} \in \im(\varphi)$. Finally, we know $1_{G^\prime} \in \im(\varphi)$\\ because $\varphi(1_G) = 1_{G^\prime}$.\retTwo
	\end{myIndent}

	\blab{Proposition:} If $\rho_1: G_1 \longrightarrow G_2$ and $\rho_2: G_2 \longrightarrow G_3$ are group homomorphisms,\\ then $\rho_2 \circ \rho_1: G_1 \longrightarrow G_3$ is a group homomorphism.
\end{myIndent}

\mySepTwo

\mHeader{Lecture 6 Notes: 10/9/2024}

Let $b_1, \ldots, b_n$ be the standard basis of $\mathbb{R}^n$. Given any $\sigma \in S_n$, define a linear map $\rho(\sigma)$ on $\mathbb{R}^n$ such that $\rho(\sigma)(b_i) = b_{\sigma(i)}$. Or equivalently:

{\centering $\rho(\sigma)(\alpha_1b_1 + \ldots + \alpha_nb_n) = \alpha_{\sigma^{-1}(1)}b(1) + \ldots + \alpha_{\sigma^{-1}(n)}b(n)$ \retTwo\par}

Then $\rho$ is a group homomorphism from $S_n$ to $GL_n(\mathbb{R})$.
\begin{myIndent}\hTwo
	The proof for this is hopefully obvious.\retTwo
\end{myIndent}

Noting that $\det: GL_n(\mathbb{R}) \longrightarrow \mathbb{R}^{\times}$ is a group homomorphism, given any $\sigma \in S_n$\\ we define the \udefine{sign} of the permutation: $\sgn(\sigma) = \det(\rho(\sigma))$. Note that by the\\ proposition at the end of the last lecture, we know $\sgn$ is a group homomorphism.

\begin{myIndent}\hTwo
	\blab{Claim:} $\im(\sgn) = \{1, -1\}$.
	
	\begin{myIndent}\hThree
		Proof:\\
		Because $S_n$ is finite, we know all $\sigma \in S_n$ have finite order. Thus, consider any\\ $\sigma \in S_n$ with order $k$. Then we have that:
		
		{\centering $\sigma^k = 1 \Longrightarrow \rho(\sigma^k) = \rho(\sigma)^k = \rho(1)$.\retTwo\par}
		
		In turn, $\det(\rho(\sigma)^k) = \det(\rho(\sigma))^k = \det(\rho(1))$. So $\sgn(\sigma)^k = 1$. But since\\ $\sgn(\sigma) \in \mathbb{R}$, we must have that $\sgn(\sigma) = \pm 1$.\retTwo
	\end{myIndent}
\end{myIndent}

The kernel of the determinant homomorphism: $\det: GL_n(\mathbb{R}) \longrightarrow \mathbb{R}^\times$ is called the \udefine{special linear group} $SL_n(\mathbb{R})$.\retTwo

The kernel of the sign homomorphism $\sgn: S_n \longrightarrow \{-1, 1\}$ is called the \udefine{alternating group}: $A_n$. Also, we call the elements of $A_n$ \udefine{even permutations}.\newpage

Suppose $H \subseteq G$ is a subgroup and $a \in G$. Then:\\ [-12pt]

{\centering$aH = \{g \in G \mid \exists h \in H \suchthat g = ah\}$,\\ [4pt]\par}

is called a \udefine{left coset} of $H$ in $G$. One can similarly define a \udefine{right coset} $Ha$. Then analogous theorems can be proven.\retTwo


\begin{myIndent}\hTwo
	\blab{Proposition}: Suppose $\varphi: G \longrightarrow G^\prime$ is a group homomorphism, and let\\ $K = \ker(\varphi)$. Then the following statements are equivalent for all $a, b \in G$:
	\begin{itemize}
		\item[$1$.] $\varphi(a) = \varphi(b)$
		\item[$2$.] $a^{-1}b \in K$
		\item[$3$.] $b \in aK$
		\item[$4$.] $aK = bK$
	\end{itemize}

	\begin{myIndent}\hThree
		Proof:\\
		($1 \Longrightarrow 2$) If $\varphi(a) = \varphi(b)$, then:

		{\centering $\varphi(a^{-1}b) = \varphi(a^{-1})\varphi(b) = \varphi(a^{-1})\varphi(a) = \varphi(a^{-1}a) = 1$.\retTwo\par}
		
		So $a^{-1}b \in K$.\retTwo

		($2 \Longrightarrow 3$) If $a^{-1}b \in K$, then $b = a(a^{-1}b) \in aK$.\retTwo

		($3 \Longrightarrow 4$) Suppose $b = ak$ for some $k \in K$. Then firstly, note that for all $c \in aK$, if $h \in K$ satisfies $c = ah$, then $c = akk^{-1}h = b(k^{-1}h)$. This shows that $aK \subseteq bK$. As for the other inclusion, note that $b = ak \Longrightarrow a = bk^{-1}$. So $a \in bK$ and we can repeat the same reasoning as before.
		
		\begin{myTindent}\teachComment
			This is actually a special case of the first corollary below.\retTwo
		\end{myTindent}

		$(4 \Longrightarrow 1)$ If $aK = bK$, then we know there exists constants $k_1, k_2 \in K$ such that $ak_1 = bk_2$. In turn, $\varphi(a) = \varphi(ak_1) = \varphi(bk_2) = \varphi(b)$.\retTwo
	\end{myIndent}

	\blab{Lemma:} Suppose $H \subseteq G$ is a subgroup, $x \in G$, and $g \in xH$. Then $xH = gH$.

	\begin{myIndent}\hThree
		Proof:\\
		Let $g = xh^\prime$ where $h^\prime \in H$. Then $gh = xh^\prime h \in xH$ for all $h \in H$. Hence,\\ $gH \subseteq xH$. Conversely $x = g(h^\prime)^{-1}$. So $x \in gH$ and we can do the same\\ reasoning as before to show that $xH \subseteq gH$.\retTwo
	\end{myIndent}

	\blab{Corollary:} Suppose $H \subseteq G$ is a subgroup and $x, y \in G$. If $xH \cap yH \neq \emptyset$, then $xH = yH$.

	\begin{myIndent}\hThree
		Proof:\\
		Suppose $xh_1 = g = yh_2$ with $h_1, h_2 \in H$. Then $xH = gH = yH$ by the previous lemma.\retTwo
	\end{myIndent}

	\blab{Corollary:} A group homomorphism $\varphi: G \longrightarrow G^\prime$ is injective if and only if its kernel is trivial (i.e. $\ker(\varphi) = \{1\})$.

	\begin{myIndent}\hThree
		Proof:\\
		The forward implication is trivial by the definition of injectivity. As for the reverse\\ implication, suppose $\ker(\varphi) = \{1\}$. Then:
		
		{\centering $\varphi(a) = \varphi(b) \Longrightarrow a^{-1}b \in \ker(\varphi) = \{1\} \Longrightarrow a^{-1}b = 1$.\newpage\par}
		
		It follows that $a = b$.\retTwo
	\end{myIndent}
\end{myIndent}

Suppose $G$ is a group and $a, g \in G$. Then $gag^{-1}$ is called the \udefine{conjugate} of $a$ by $g$.\retTwo

Suppose $G$ is a group and $N \subseteq G$ is a subgroup. The subgroup $N$ is \udefine{normal} if $gng^{-1} \in N$ for all $n \in N$ and $g \in G$.

\begin{myIndent}\hTwo
	\blab{Proposition:} Suppose $\varphi: G \longrightarrow G^\prime$ is a group homomorphism. Then $\ker(\varphi) \subseteq G$ is a normal subgroup.
	
	\begin{myIndent}\hThree
		Proof:\\
		Suppose $a \in \ker(\varphi)$ and $g \in G$. Then $gag^{-1} \in \ker(\varphi)$ because:

		{\center $\varphi(gag^{-1}) = \varphi(g)\varphi(a)\varphi(g)^{-1} = \varphi(g)\varphi(g)^{-1} = 1$ \retTwo\par}
	\end{myIndent}
\end{myIndent}

\mHeader{Lecture 7 Notes: 10/11/2024}

You already know what an \udefine{abelian group} is. Note that every subgroup of an abelian group is normal because $ga = ag \Longrightarrow gag^{-1} = a$\retTwo

Given a group $G$, define $Z(G) \coloneq \{z \in G \mid zx = xz \text{ for all } x \in G\}$, Then $Z(G)$ is a normal subgroup of $G$ called the \udefine{center} of $G$.

\begin{myIndent}\hTwo
	Proof that $Z(G)$ is a subgroup:
	\begin{myIndent}\hThree
		We know $1 \in Z(G)$.\\ 
		Also if $z \in Z(G)$, then for all $x \in G$ we have that:
		
		{\centering $zx = xz \Rightarrow z^{-1}zxz^{-1} = z^{-1}xzz^{-1} \Rightarrow xz^{-1} = z^{-1}x$.\retTwo\par}
	
		Finally if $y, z \in Z(G)$, then for all $x \in G$ we have that:
	
		{\centering $(zy)x = z(yx) = z(xy) = (zx)y = (xz)y = x(zy)$ \retTwo\par}
	\end{myIndent}
\end{myIndent}

Suppose $n \in \mathbb{Z}_+$. Then $\mu_n = \{z \in \mathbb{C}^\times \mid z^n = 1\}$ is a subgroup under complex\\ multiplication. ($\mu_n$ is called the \udefine{$n$th roots of unity}.)

\begin{myIndent}\hTwo
	Note that the elements of $\mu_n$ are all the numbers of the form $e^{\frac{2\pi ia }{n}}$ where $a \in \mathbb{Z}$.\retTwo

	Also, $\mu_n$ has $n$ elements and is cyclic (it is generated by $e^{\frac{2pi}{n}}$). This shows that for all $n \in \mathbb{Z}_+$ there is a cyclic group with $n$ elements.\retTwo
\end{myIndent}

\exOne

\mySepTwo

\blab{Examples of group isomorphisms:} (I'm skipping writing down most of these cause they're not interesting)\retTwo

Let $G$ be an arbitrary group and $g \in G$. Then define $\rho_g: G \longrightarrow G$ such that\\ $\rho_g(x) = gxg^{-1}$. Then $\rho_g$ is a group isomorphism.

\begin{myIndent}\exTwoP
	Proof:\\ [-20pt]
	\begin{itemize}
		\item Homomorphism: $\rho_g(a)\rho_g(b) = gag^{-1}gbg^{-1} = gabg^{-1} = \rho_g(ab)$.
		\item Surjectivity: given $y \in G$, set $x = g^{-1}yg$. Then $\rho_g(x) = y$.
		\item Injectivity: $gag^{-1} = gbg^{-1} \Rightarrow g^{-1}gag^{-1}g = g^{-1}gbg^{-1}g \Rightarrow a = b$.\newpage
	\end{itemize}
\end{myIndent}

Fix a positive integer $n$ and let $a$ be an integer with $\gcd(a, n) = 1$. Then define\\ $\varphi_a: \mu_n \longrightarrow \mu_n$ by $\varphi_a(\zeta) = \zeta^a$. This is an isomorphism.

\begin{myIndent}\exTwoP
	Proof:\\ [-20pt]
	\begin{itemize}
		\item homomorphism: since multiplication in $\mathbb{C}$ is commutative, 
		
		{\centering $\varphi_a(\zeta_1\zeta_2) = (\zeta_1\zeta_2)^a = \zeta_1^a\zeta_2^a = \varphi_a(\zeta_1)\varphi_a(\zeta_2)$.\retTwo\par}

		\item Bijectivity: we know there exists $r, s \in \mathbb{Z}$ such that $ar + ns = 1$. So define\\ $\varphi_r: \mu_n \longrightarrow \mu_n$. Then note that: $\varphi_r(\varphi_a(\zeta)) = \zeta^{ar} = \varphi_a(\varphi_r(\zeta))$ and\\ $\zeta^{ar} = \zeta^{1-ns} = \zeta(\zeta^n)^{-s} = \zeta \cdot 1^{-s} = \zeta$. So, $\varphi_r = \varphi_a^{-1}$. Hence, $\varphi_a$ is bijective.\retTwo
	\end{itemize}
\end{myIndent}

\hOne
If two groups are \udefine{isomorphic}, we write $G \iso G^\prime$.\retTwo

An isomorphism from a group $G$ to itself is called an \udefine{automorphism}.\retTwo

Two elements $x, y$ of a group $G$ are \udefine{conjugate} if there exists $g \in G$ such that $y = gxg^{-1}$.

\begin{myIndent}\hTwo
	Conjugates behave similar. For example, conjugates have the same order.\retTwo
\end{myIndent}

\mySepTwo

\begin{myIndent}\hTwo
	\blab{Lemma}: Suppose $n \geq 1$ is an integer and $C_n = \langle x \rangle$ is a cyclic group generated by an element $x \in C_n$ (to be clear, this notation tells us that $C_n$ has $n$ elements). Suppose $G$ is also a group and $y \in G$ satisfies that $y^n = 1$. Then there is a unique group homomorphism $\varphi: C_n \longrightarrow G$ with $\varphi(x) = y$.

	\begin{myIndent}\hThree
		Proof:\\
		Define $\varphi(x^k) = y^k$ for all $k \in \mathbb{Z}$. This is well defined because\\ $x^r = x^s \Longrightarrow r - s \in n\mathbb{Z}$. So given that $x^r = x^s$, there exists\\ $q \in \mathbb{Z}$ with $r = s + qn$ and $y^r = y^{s + qn} = y^s(y^n)^q = y^s$.\retTwo

		Having shown that this is well-defined, it's now trivial to see this is a group\\ homomorphism.

		{\centering $\varphi(x^jx^k) = \varphi(x^{j + k}) = y^{j+k} = y^jy^k = \varphi(y^j)\varphi(y^k)$ \retTwo\par}

		It should also be noted that $\varphi$ is unique. This is because the fact that $\varphi$ is a\\ homomorphism means that $\varphi(x^k) = \varphi(x^{k-1})\varphi(x) = \ldots = (\varphi(x))^k = y^k$.
	\end{myIndent}

	\blab{Proposition}: Suppose $G = \langle x \rangle$ and $G^\prime = \langle y \rangle$ are both cyclic of size $n$. Then $G$ is isomorphic to $G^\prime$.\retTwo

	\begin{myIndent}\hThree
		Proof:\\
		Let $\varphi: G\longrightarrow G^\prime$ be the group homomorphism with $\varphi(x) = \varphi(y)$. It is clearly sujective, and since both $G$ and $G^\prime$ have $n$ elements, it must also be injective.\retTwo
	\end{myIndent}

	\blab{Corollary}: Every cyclic group of size $n$ is isomorphic to $\mu_n$.\retTwo
\end{myIndent}

In a similar fashion, we can show every infinite cyclic group to be isomorphic to the integers $\mathbb{Z}$. (Note on notation: if I just write $\mathbb{Z}$, $\mathbb{R}$, or $\mathbb{C}$, assume I'm refering to the groups under addition.)\newpage

\exOne
Proof that $\mathbb{R}$ is not isomorphic to $\mathbb{R}^\times$.
\begin{myIndent}\exTwoP
	Suppose $\rho: \mathbb{R} \longrightarrow \mathbb{R}^\times$ is a group homomorphism. Then\\ $\rho(x) = \rho(\frac{x}{2} + \frac{x}{2}) = \rho(\frac{x}{2})^2 > 0$. So $\rho(x) > 0$ for all $x$.\retTwo
\end{myIndent}

\hOne
\mySepTwo

\mHeader{Lecture 8 Notes: 10/14/2024}

I already know what partitions, equivalence relations, and equivalence classes are.\retTwo


\exOne
\blab{Examples:} Let $G$ be a group and $H \subseteq G$ is a subgroup.
\begin{itemize}
	\item The collection of cosets of $H$ in $G$ is a partition of $G$.
	\begin{myIndent}\exTwo
		To see why look at the second lemma on page 10.\\
	\end{myIndent}
	\item Define $a \sim b$ if $\exists h \in H$ so that $b = ah$. Then $\sim$ is an equivalence relation.
	\begin{myIndent}\exP
		To see why:
		\begin{itemize}
			\item[$\circ$] $1 \in H \Rightarrow a = a1 \Rightarrow a \sim a$
			\item[$\circ$] $a \sim b \Rightarrow \exists h \in H \suchthat b = ah \Rightarrow a = bh^{-1} \Rightarrow b \sim a$
			\item[$\circ$] $a \sim b \sim c \Rightarrow \exists h_1, h_2 \in H \suchthat b = ah_1,\myHS c = bh_2 \Rightarrow c = ah_1h_2 \Rightarrow a \sim c$\\
		\end{itemize}
	\end{myIndent}
	\item Define $a \sim b$ if $b$ is conjugate to $a$. Then $\sim$ is an equivalence relation.
	\begin{myIndent}
		To see why:
		\begin{itemize}
			\item[$\circ$] $a = 1a1^{-1} \Rightarrow a \sim a$
			\item[$\circ$] $a \sim b \Rightarrow \exists g \in G \suchthat a = gbg^{-1} \Rightarrow b = g^{-1}a(g^{-1})^{-1} \Rightarrow b \sim a$
			\item[$\circ$] $a \sim b \sim c \Rightarrow \exists g, h \in G \suchthat b = gag^{-1},\myHS c = hbh^{-1}$. So:
			
			{\centering$c = hgag^{-1}h^{-1} = (hg)a(hg)^{-1} \Rightarrow a \sim c$\retTwo\par}
		\end{itemize}
	\end{myIndent}

	\item If $f:S\longrightarrow T$ is a map of sets define $a \sim b$ if $f(a) = f(b)$.\retTwo
\end{itemize}

\hOne 
Suppose $S$ is a set with an equivalent relation $\sim$. Given $a \in S$, we denote the\\ equivalence class of $a$ as $C_a$.\retTwo

We define the \udefine{quotient set} $\overline{S}$ to be the set whose elements are the equivalence classes $C_a$ of $\sim$ on $S$.\retTwo

\begin{myIndent}\hTwo
	Suppose $\varphi: G \longrightarrow G^\prime$ is a group homomorphism. If $a, b \in G$, we write $a \equiv b$ if $\varphi(a) = \varphi(b)$. Note that letting $K = \ker(\varphi)$, we have that $a \equiv b$ if and only if $aK = bK$. So $\equiv$ is an equivalence relation.\newpage 
\end{myIndent}

Given a group $G$ and subgroup $H$, we denote $G/H$ for the set of cosets of $H$. The \udefine{index} of a subgroup $H$ of a group $G$ is the number of left cosets of $H$ in $G$. It is denoted $[G: H]$.

\begin{myIndent}\hTwo
	\blab{Lemma 3w5:} Let $H$ be a subgroup of a group $G$. Then every left coset of $H$ in $G$ has the same cardinality.
	\begin{myIndent}\hThree
		Proof:\\
		Suppose $xH$ and $yH$ are two cosets. Define $f: xH \longrightarrow yH$ as $f(g) = yx^{-1}g$. Then $f$ is a bijection.\retTwo
	\end{myIndent}

	\blab{Theorem 3w6:} Suppose $G$ is a finite group and $H$ is a subgroup of $G$. Then\\ $|G| = [G:H]|H|$.
	
	\begin{myIndent}\hThree
		Since each coset is disjoint and has the same cardinality, this is pretty trivial.\retTwo
	\end{myIndent}

	\blab{Lagrange's theorem} If $G$ is a finite group and $H$ is a subgroup of $G$, then the order of $H$ divides the order of $G$.\retTwo

	\blab{Corollary 3w8:} Suppose $G$ is a finite group and $g \in G$. Then the order of $g$ divides $|G|$.
	
	\begin{myIndent}\hThree
		Proof:\\
		Let $H = \langle g \rangle$ and apply Lagrange's theorem.\retTwo
	\end{myIndent}

	\blab{Corollary 3w9:} Suppose $p$ is a prime integer and $G$ is a group of order $p$. Let $a$ be an element of $G$ distinct from the identity. Then all of $G$ is the cyclic group generated by $a$.

	\begin{myIndent}\hThree
		Proof:\\
		Let $H = \langle a \rangle$. Then by Lagrange's theorem, we know $|H|$ divides $|G| = p$. But $|H| \neq 1$. So $|H| = p$.\retTwo
	\end{myIndent}
\end{myIndent}

\mHeader{Lecture 9 Notes: 10/16/2024}

\begin{myIndent}\hTwo
	\blab{Lemma 3w10:} Suppose $\varphi: G \longrightarrow G^\prime$ is a group homomorphism. Then\\ $|\im(\varphi)| = [G: \ker{\varphi}]$.
	
	\begin{myIndent}\hThree
		Proof:\\
		Let $K = \ker(\varphi)$. Then $\varphi(a) = \varphi(b)$ if and only if $aK = bK$. So, there is a\\ bijective correspondance between the left cosets of $K$ and $\im(\varphi)$.\retTwo
	\end{myIndent}

	\blab{Corollary 3w11:} Let $\varphi: G \longrightarrow G^\prime$ be a homomorphism of finite groups. Then:
	\begin{enumerate}
		\item $|G| = |\ker(\varphi)|\cdot |\im(\varphi)|$
		\item $|\ker(\varphi)|$ divides $|G|$.
		\item $|\im(\varphi)|$ divides $|G|$ and $|G^\prime|$.
	\end{enumerate}

	\begin{myIndent}\hThree
		Proof:\\
		Substituting in $[G: \ker(\varphi)] = |\im(\varphi)|$ into theorem 3w6, we get that\\ $|G| = |\im(\varphi)|\cdot |\ker(\varphi)|$. The rest follows trivially from and Lagrange's theorem.\newpage
	\end{myIndent}

	\blab{Theorem 3w12:} Suppose $G \subseteq H \subseteq K$ with $G$ being a finite group, $H$ being a subgroup of $G$, and $K$ being a subgroup of $H$. Then $[G:K] = [G:H][H:K]$.

	\begin{myIndent}\hThree
		Proof:\\
		Suppose $[G:H] = m$ and $[H:K] = n$. Then there exists $g_i \in G$ and $h_j \in H$ satisfying that $G = g_1H \cup \ldots \cup g_mH$ and $H = h_1K \cup \ldots \cup h_mK$ where each union is of disjoint sets.\retTwo

		Now note that $\{g_ih_jK \mid j \in \{1, \ldots, n\}\}$ is a partition of $g_iH$. To prove this, note that given any $x \in g_iH$, there exists $h \in H$ such that $x = g_ih$. But note that for some $h_j$ and $k \in K$, we have that $h = h_j k$. So $x \in g_ih_j k$ for some $h_j \in K$. At the same time, we can fairly trivially see that $g_ih_jK \subseteq g_iH$ for all $j$. And, we already showed that nonequal cosets are disjoint.\retTwo

		So, $G = \bigcup\limits_{i=1}^m \bigcup\limits_{j=1}^n g_ih_j K$.\retTwo
	\end{myIndent}

	\blab{Proposition 3w13:} Let $H$ be a subgroup of a group $G$. The following are equivalent.
	\begin{enumerate}
		\item $H$ is normal.
		\item $gHg^{-1} = H$ for all $g \in G$
		\begin{myTindent}
			{\myComment (It's fairly trivial to see that $(aH)b = a(Hb)$ for all $a, b\in G$).}
		\end{myTindent}
		\item $gH = Hg$ for all $g \in G$.
		\item Every left coset of $G$ is a right coset of $G$ (and vice versa)
	\end{enumerate}

	\begin{myIndent}\hThree
		Proof:\\
		(1) $\Longrightarrow$ (2) 
		\begin{myIndent}
			If $H$ is normal, then by definition $gHg^{-1}, g^{-1}Hg \subseteq H$. In turn,\\ $H = g^{-1}(gHg^{-1})g \subseteq g^{-1}(H)g$. So $gHg^{-1} = H$.\retTwo
		\end{myIndent}

		(2) $\Longrightarrow$ (1)\\
		(2) $\Longleftrightarrow$ (3)\\
		(3) $\Longrightarrow$ (4)
		\begin{myIndent}
			These are trivial.\retTwo
		\end{myIndent}

		(4) $\Longrightarrow$ (1)
		\begin{myIndent}
			Suppose $gH = Hg^\prime$. Then $g \in Hg^\prime$ because $g = g1 \in gH$. So,\\ $Hg = Hg^\prime = gH$.\retTwo
		\end{myIndent}
	\end{myIndent}

	\blab{Proposition 3w14:} Suppose $G$ is a group.
	\begin{enumerate}
		\item If $g \in G$ and $H$ is a subgroup of $G$, then $gHg^{-1}$ is a subgroup of $G$.
		\item If $G$ has one subgroup of order $r$, that subgroup is normal.
	\end{enumerate}

	\begin{myIndent}\hThree
		Conjugation by $g$ is a group automorphism. So the image (which equals $gHg^{-1}$) of that homomorphism restricted to $H$ is a subgroup of $G$.\retTwo

		The other claim comes from the fact that if $|H| = |gHg^{-1}|$. So if $G$ only has one subgroup of order $r$ and $H$ is a subgroup of order $r$, then $|gHg^{-1}| = r$ implies that $gHg^{-1} = H$.\newpage
	\end{myIndent}
\end{myIndent}

\blab{Modular Arithmetic}\retTwo

One says two integers $a, b$ are \udefine{equivalent modulo $n$} if $a + n\mathbb{Z} = b + n\mathbb{Z}$. This is the same as saying $a - b \in n\mathbb{Z}$. One writes $a \equiv b \mMod{n}$.

\begin{myIndent}\hTwo
	\blab{Proposition 3w16:} Suppose $a_1 \equiv b_1 \mMod{n}$ and $a_2 \equiv b_2 \mMod{n}$. Then:
	
	\begin{itemize}
		\item $a_1 + a_2 \equiv b_1 + b_2 \mMod{n}$
		\item $a_1a_2 \equiv b_1b_2 \mMod{n}$
	\end{itemize}

	\begin{myIndent}\hThree
			Proof:\\
			We know $b_1 = a_1 + k_1n$ and $b_2 = a_2 K k_2n$ for some integers $k_1, k_2$. Thus:\fontsize{11.5}{13.5}\selectfont
			\begin{itemize}
				\item $b_1 + b_2 = a_1 + a_2 + (k_1 + k_2)n$
				\item $b_1b_2 = a_1a_2 + a_1k_2n + a_2k_1n + k_1k_2n^2 = a_1a_2 + (a_1k_2 + a_2k_1 + k_1k_2n)n$\retTwo
			\end{itemize}
	\end{myIndent}
\end{myIndent}

Fixing $n$, then given $a \in \mathbb{Z}$, we denote it's equivalence class $\overline{a} = a + n\mathbb{Z}$.\\ (specifically $a + n\mathbb{Z}$ is a coset of $n\mathbb{Z}$). Note that $\mathbb{Z}/n\mathbb{Z} = \{\overline{0}, \overline{1}, \ldots, \overline{n-1}\}$.\retTwo

Given $\overline{a}$ and $\overline{b}$ in $\mathbb{Z}/n\mathbb{Z}$, we define $\overline{a} + \overline{b} = \overline{a + b}$ and $\overline{a} \cdot \overline{b} = \overline{ab}$. This is well defined by the previous proposition.\retTwo

\begin{myIndent}\hTwo
	\blab{Proposition 3w17:} Fix a positive integer $n$,
	\begin{itemize}
		\item Addition and multiplication in $\mathbb{Z}/n\mathbb{Z}$ is commutative and associative.
		\item Multiplication in $\mathbb{Z}/n\mathbb{Z}$ distributes over addition.
		\item The class $\overline{0}$ is an identity for addition, and every element of $\mathbb{Z}/n\mathbb{Z}$ has an\\ additive inverse.
		\item The class $\overline{1}$ is an identity for multiplication.
	\end{itemize}
	
	\begin{myIndent}\hThree
		This all follows from the fact that $\mathbb{Z}$ has these properties.\retTwo
	\end{myIndent}

	\blab{Proposition 3w18:} The set $\mathbb{Z}/n\mathbb{Z}$ with law of composition being addition is a group. It is cyclic of order $n$.
	
	\begin{myIndent}\hThree
		This is because it is generated by $\overline{1}$.
	\end{myIndent}
\end{myIndent}

Note that the map $\rho: \mathbb{Z}/n\mathbb{Z} \longrightarrow \mu_0$ given by $\rho(a + n\mathbb{Z}) = e^{\frac{2\pi i a}{n}}$ is an isomorphism.\retTwo

Let $(\mathbb{Z}/n\mathbb{Z})^\times$ be the set of all $x \in \mathbb{Z}/n\mathbb{Z}$ with multiplicative inverses.\retTwo

{\begin{myIndent}\hTwo
	\blab{Lemma 3w20:} Suppose $n \in \mathbb{Z}$ is nonzero and $a \in \mathbb{Z}$. Then there exists $b \in \mathbb{Z}$ so that $ab \equiv 1 \mMod{n}$ if and only if $\gcd(a, n) = 1$.
	
	\begin{myIndent}\hThree
		Proof:\\
		If $b$ exists, then $ab = 1 + kn$ for some $k \in \mathbb{Z}$. So, $ab - kn = 1$, meaning\\ $\gcd(a, n) = 1$. You can just flip that reasoning to get the other direction\\ implication.\retTwo
	\end{myIndent}

	\blab{Proposition 3w21:} The set $(\mathbb{Z}/n\mathbb{Z})^\times$ is a group under multiplication.

	\begin{myIndent}\hThree
		Proof:\\
		This is a special case of homework 1 problem 1.\newpage
	\end{myIndent}

	\blab{Corollary 3w22:} If $p$ is a prime number, the size of $(\mathbb{Z}/p\mathbb{Z})^\times$ is $p - 1$. Consequently if $p \hspace{-0.1em}\not\divides a$, then $a^{p-1} \equiv 1 \mMod{p}$.

	\begin{myIndent}\hThree
		Proof:\\
		The first part is just applying lemma 3w20. To get the second part, note that the order of $a$ must divide $p - 1$. If $|\langle a \rangle| = \frac{p - 1}{d}$, then it follows that:
		
		{\centering $(a^{\frac{p - 1}{d}})^d \equiv a^{p-1} \equiv 1 \mMod{p}$.\retTwo\par}

		Hence, $a^{p-1} \equiv 1 \mMod{p}$ for all $a \in (\mathbb{Z}/p\mathbb{Z})^{\times}$.\retTwo
	\end{myIndent}
\end{myIndent}}

More generally, we define $\varphi(n) = |\left\{x \in \mathbb{Z} \mid 1 \leq x < n \text{ and } \gcd(x, n) = 1\right\}|$. This is called \udefine{Euler's totient function}. Then:

\begin{myIndent}\hTwo
	\blab{Corollary 3w23:} Suppose $\gcd(a, n) = 1$. Then the size of $(\mathbb{Z}/n\mathbb{Z})^\times$ is $\varphi(n)$ and\\ $a^{\varphi(n)} \equiv 1 \mMod{n}$.\retTwo
\end{myIndent}

\mySepTwo

Now if you are paying attention, the group of integers under addition module $n$ can be thought of as a special case of the more general theory below.\retTwo

Suppose $G$ is a group and $N$ is a normal subgroup. we define $\overline{G} = G / N$. And if $a \in G$, we define $\overline{a} = aN \in G / N$.\retTwo

Let $\pi: G \longrightarrow \overline{G}$ denote the surjective map $\pi(a) = \overline{a}$ (this is the \udefine{canonical map}).

\begin{myIndent}\hTwo
	\blab{Theorem 3w24:} There is a law of composition on $\overline{G}$ that makes it into a group such that $\pi: G \longrightarrow \overline{G}$ is a surjective group homomorphism whose kernel is $N$.

	\begin{myIndent}\hThree
		Proof:\\
		\blab{Lemma 3w25:} The formula $(aN)\cdot(bN) = (abN)$ is a well-defined law of composition\\ on $\overline{G}$.
		
		\begin{myIndent}\hFour
			Proof:
			Suppose $a^\prime = an_1$ and $b^\prime = bn_2$. Then:

			{\centering $a^\prime b^\prime = an_1bn_2 = a(bb^{-1})n_1bn_2 = ab(b^{-1}n_1b)n_2 \in abN$ \retTwo\par}

			This works because $b^{-1}n_1b \in N$ since $N$ is normal.\retTwo
		\end{myIndent}

		\blab{Lemma 3w26:} Given the law of composition defined above and the set $\overline{G}$, we have the following:
		\begin{enumerate}
			\item The set $1N = N$ is an identity for the law of composition on $\overline{G}$.
			\item The inverse of $aN$ is $a^{-1}N$.
			\item The law of composition on $\overline{G}$ is associative.
		\end{enumerate}

		\begin{myIndent}\hFour
			Proof:\\
			All of these follow directly from the the fact that $G$ is a group.\retTwo
		\end{myIndent}

		Now that we know that $\overline{G}$ is a group when equipped with the above law of\\ composition, it's pretty clear that $\pi$ is a surjective group homomorphism. All that's left to do now is show that $\ker(\pi) = N$. To do this, note that $\pi(a) = aN = 1N$ if and only if $a \in N$.\newpage
	\end{myIndent}

	\blab{First Isomorphism Theorem:} Let $\varphi: G \longrightarrow G^\prime$ be a group homomorphism with kernel $N$, and let $\pi: G \longrightarrow \overline{G} = G / N$ be the canonical map. Then there is a unique group homomorphism $\overline{\varphi}: \overline{G} \longrightarrow G^\prime$ for which $\varphi = \overline{\varphi} \circ \pi$. The map $\overline{\varphi}: \overline{G} \longrightarrow \varphi(G)$ is an isomorphism.

	\begin{myIndent}\hThree
		Proof:\\
		Note that by a proposition on page 11, we know that $N$ is normal.\retTwo
		\begin{itemize}
			\item \blab{Uniqueness:} In order for $\varphi = \overline{\varphi} \circ \pi$, we must have that $\overline{\varphi}(\overline{a}) = \varphi(a)$. Thus, if\\ $\overline{\varphi}$ exists, then it is unique.
			\item \blab{Well-defined:} Define $\overline{\varphi}(aN) = \varphi(a)$. THis is well-defined as $\varphi(an) = \varphi(a)$ due to $n \in \ker(\varphi)$.
			\item \blab{Group homomorphism:}
			
			{\centering$\overline{\varphi}((aN)(bN)) = \overline{\varphi}(abN) = \varphi(ab) = \varphi(a)\varphi(b) = \overline{\varphi}(aN)\overline{\varphi}(bN)$.\par}

			\item \blab{Isomorphism:} $\overline{\varphi}$ is injective because $\overline{\varphi}(aN) = \varphi(a) = 1$ implies that $a \in N$. So the kernel is trivial. Also, the image of $\overline{\varphi}$ is $\varphi(G)$.\retTwo
		\end{itemize}
	\end{myIndent}
\end{myIndent}

\exOne
Some applications of the above theorem:

\begin{itemize}
	\item The quotient of $GL_n(\mathbb{R})$ by the normal subgroup $SL_n(\mathbb{R})$ is isomorphic to $\mathbb{R}^\times$.
	
	\item There's a longer problem here that I'm skipping for now. Maybe I'll cover it on\\ page \_\_\_.
\end{itemize}

\hOne\mySepTwo

Suppose $G, H$ are groups. One can define a law of composition on $G \times H$ as\\ $(g_1, h_1)(g_2, h_2) = (g_1g_2, h_1h_2)$.\\ [-10pt]
\begin{myIndent}\hTwo
	\blab{Proposition 3w28:} This makes $G \times H$ a group. The identity is $(1, 1)$ and the inverse of $(g, h) = (g^{-1}, h^{-1})$.\retTwo
\end{myIndent}

If $R$ is a group and $\varphi_1: R \longrightarrow G$ and $\varphi_2: R \longrightarrow G$ are group homomorphisms, then $\varphi: R \longrightarrow G \times H$ given by $\varphi(r) = (\varphi_1(r), \varphi_2(r))$ is a group homomorphism.

\begin{myTindent}\begin{myTindent}\myComment
	Hopefully this is obvious. So I'm not proving this.\retTwo
\end{myTindent}\end{myTindent}

\begin{myIndent}\hTwo
	\blab{Lemma 3w29:} Suppose $m, n$ are positive integers with $m$ dividing $n$. Then the map $\mathbb{Z} / n\mathbb{Z} \longrightarrow \mathbb{Z}/m\mathbb{Z}$ sending $a + n\mathbb{Z}$ to $a + m\mathbb{Z}$ is a well-defined surjective group homomorphism.
	
	\begin{myIndent}\hThree
		Proof:\\
		To start, note that this is well defined because if $a \in b + n\mathbb{Z}$, then we know\\ $a = b + nr$ for some $r \in \mathbb{Z}$. Then since $n = md$ for some $d \in \mathbb{Z}$, it follows that\\ $a = b + m(dr) \in b + m\mathbb{Z}$. In other words, $a \in b + n\mathbb{Z} \Longrightarrow a + m\mathbb{Z} = b + m\mathbb{Z}$.\retTwo

		To see that this is a group homomorphism, just note that:

		{\centering\fontsize{11.5}{13.5} $(a + nr) + (b + ns) = (a + m(dr)) + (b + m(ds)) = (a + b) + m(dr + ds) = (a + b) + n(r + s)$ \retTwo\par}

		Finally, it's pretty trivial to see that this is surjective.\newpage
	\end{myIndent}
\end{myIndent}

\mHeader{Lecture 11 Notes: 10/21/2024}

\begin{myIndent}\hTwo
	\blab{Chinese Remainder Theorem:} Suppose $r, s$ are coprime positive integers. Then the map $\mathbb{Z} / (rs)\mathbb{Z} \longrightarrow (\mathbb{Z} / r\mathbb{Z}) \times (\mathbb{Z} / s\mathbb{Z})$ given by $n + rs\mathbb{Z} \mapsto (n + r\mathbb{Z}, n + s\mathbb{Z})$ is an isomorphism.

	\begin{myIndent}\hThree
		Proof:\\
		Here is an equivalent statement: Suppose $r, s$ are coprime positive integers. Then the map $\mathbb{Z} \longrightarrow (\mathbb{Z} / r\mathbb{Z}) \times (\mathbb{Z} / s\mathbb{Z})$ sending $n \in \mathbb{Z}$ to $(n + r\mathbb{Z}, n + s\mathbb{Z})$ is surjective with $(rs)\mathbb{Z}$ as it's kernel.

		
		\begin{myIndent}\hFour
			Proof:\\
			To start, note that the maps $\mathbb{Z} \longrightarrow \mathbb{Z} / r\mathbb{Z}$ and $\mathbb{Z} \longrightarrow \mathbb{Z} / s\mathbb{Z}$ such that\\ $a \mapsto a + r\mathbb{Z}$ and $a \mapsto a + s\mathbb{Z}$ respectively are both group homomorphisms.      Combining this with what was discussed on the last page, we know that the map sending $n \in \mathbb{Z}$ to $(n + r\mathbb{Z}, n + s\mathbb{Z})$ is a group homomorphism.\retTwo

			
			\begin{myTindent}\myComment
				Side note: under additive notation, the law of composition of the product $G \times H$ of two groups $G$ and $H$ is:
				
				{\centering$(g_1, h_1) + (g_2, h_2) = (g_1 + g_2, h_1 + h_2)$.\retTwo\par}
			\end{myTindent}
			
			Now since $\gcd(r, s) = 1$, there exists $a, b \in \mathbb{Z}$ such that $ar + bs = 1$. Now set $u = bs$ and $v = ar$. Then note that $u \mapsto (1, 0)$ and $v \mapsto (0, 1)$. It follows that $xu + yv = (x + r\mathbb{Z}, y + s\mathbb{Z})$. So the map is surjective.\retTwo

			Meanwhile, note that if $r \divides n$ and $s \divides n$, then we can say that $s \divides r(\frac{n}{r})$. But now note that since $\gcd(s, r) = 1$, we must have that $s \divides \frac{n}{r}$. So, $rs \divides n$. Similarly, if $rs \divides n$, we obviously have that $r \divides n$ and $s \divides n$. So it follows that the kernel of this map is $(rs)\mathbb{Z}$.\retTwo
		\end{myIndent}

		Now the reason why this statement is equivalent to the original is that we can now use the first isomorphism theorem to state that our original map from $\mathbb{Z} / (rs)\mathbb{Z}$ to\\ $(\mathbb{Z} / r\mathbb{Z}) \times (\mathbb{Z} / s\mathbb{Z})$ is an isomorphism.\retTwo
	\end{myIndent}

	\blab{Lemma 4w4:} Suppose $\varphi: G \longrightarrow G^\prime$ is a group homomorphism, and let $H^\prime \subseteq G^\prime$ be a subgroup. Let $H = \varphi^{-1}(H^\prime)$. Then:
	\begin{enumerate}
		\item $H$ is a subgroup of $G$ that contains $\ker(\varphi)$.
		\begin{myIndent}\hThree
			Proof:\\
			We know $1 \in H$. Also, if $h \in H$, then $\varphi(h^{-1}) = \varphi(h)^{-1} \in H^\prime$. So $h^{-1} \in H$. Finally, if $h_1, h_2 \in H$, then $\varphi(h_1h_2) = \varphi(h_1)\varphi(h_2) \in H^\prime$. So, $h_1h_2 \in H$.\retTwo

			Also, the fact that $\ker(\varphi) \subseteq H$ is just because $1 \in H^\prime$.\retTwo
		\end{myIndent}

		\item If $H^\prime$ is normal, then so is $H$.
		\begin{myIndent}\hThree
			Proof:\\
			We know that $\varphi(ghg^{-1}) = \varphi(g)\varphi(h)\varphi(g)^{-1} \in H^\prime$ for all $h \in H$ and $g \in G$. So, $ghg^{-1} \in H$ for all $h \in H$ and $g \in G$.\newpage
		\end{myIndent}

		\item If $H$ is normal and $\varphi$ is surjective, then $H^\prime$ is normal.
		\begin{myIndent}\hThree
			Fuck you, do this proof yourself. It's not that hard.\retTwo
		\end{myIndent}
	\end{enumerate}

	\blab{Theorem 4w5:} Let $\varphi: G \longrightarrow G^\prime$ be a surjective group homomorphism with\\ kernel $K$.
	\begin{enumerate}
		\item There is a bijective correspondance between subgroups of $G^\prime$ and subgroups of $G$ containing $K$. The correspondence is $H \mapsto \varphi(H)$ for $H \subseteq G$ and\\ $H^\prime \mapsto \varphi^{-1}(H^\prime)$ for $H^\prime \subseteq G^\prime$.
	\end{enumerate}
\end{myIndent}




























\newpage

\phantom{a} % Barrier so that I don't get struck with academic integrity violation on accident for flashing the homework answers

\newpage

\hOne
\mHeader{Homework 1: Due 10/8/2024}

\begin{enumerate}
	\item Let $S$ be a set with an associative law of composition and with an identity\\ element. Let $G = \{x \in S \mid x \text{ has an inverse}\}$. Prove that $G$ is a group with the law of composition from $S$.
	
	\begin{myIndent}\exOne
		I'll be using multiplicative notation for composition on $S$. Firstly, to prove that the law of composition on $S$ is closed over $G$, suppose $a, b \in G$, meaning there exists $a^{-1}, b^{-1} \in S$ which are inverses of $a$ and $b$ respectively. Then since $\cdot$ is associative on $S$, we know that $(b^{-1}a^{-1})ab = 1 = ab(b^{-1}a^{-1})$. So $ab$ also has an inverse, meaning $ab$.\retTwo
		
		Next, since $1$ is its own inverse, we know $1 \in G$. Also, if $x \in G$, meaning that there exists $x^{-1} \in S$, then $(x^{-1})^{-1} = x$. So $x^{-1} \in G$ as well. Finally, we know\\ that the law of composition on $G$ is associative because we assumed it was associative on $S$. Hence, we've shown that $(G, \cdot)$ is a group.\retTwo
	\end{myIndent}

	\item Let $\mathrm{SL}_2(\mathbb{Z}) = \left\{\gamma = 
	\left[\begin{smallmatrix}
		a & b \\ c & d
	\end{smallmatrix}\right] \mid a, b, c, d \in \mathbb{Z} \text{ and } \det(\gamma) = 1\right\}$. Prove that\\ multiplication of matrices makes $\mathrm{SL}_2(\mathbb{Z})$ a group.

	\begin{myIndent}\exOne
		To start, let's show that $\mathrm{SL}_2(\mathbb{Z})$ is closed under matrix multiplication.
		
		
		\begin{myIndent}\exPP
			Suppose $\gamma_1 = \left[
			\begin{smallmatrix}
				a & b \\ c & d
			\end{smallmatrix}\right]$ and $\gamma_2 = \left[
			\begin{smallmatrix}
				e & f \\ g & h
			\end{smallmatrix}\right]$ are elements of $\mathrm{SL}_2(\mathbb{Z})$. Then\\ $\gamma_1\gamma_2 = \left[
				\begin{smallmatrix}
					ae + bg & af + bh \\ ce + dg & cf + dh
				\end{smallmatrix}\right]$. Since the integers are closed under addition and\\ [2pt] multiplication, we know that all the elements of $\gamma_1\gamma_2$ are integers. Also,\\ [3pt] a fact from linear algebra is that $\det(\gamma_1\gamma_2) = \det(\gamma_1)\det(\gamma_2) = 1^2 = 1$.\\ [3pt] Hence $\gamma_1 \gamma_2 \in \mathrm{SL}_2(\mathbb{Z})$.\retTwo

				If you don't trust that fact about determinants, then you can expand out\\ the expression $(ae + bg)(cf + dh) - (ce + dg)(af + bh)$ yourself.\\ Four of the terms cancel out and the other four can be factored as\\ $(ad - bc)(eh - gf) = \det(\gamma_1)\det(\gamma_2)$.\retTwo
		\end{myIndent}

		Next, observe that $\mathrm{SL}_2(\mathbb{Z})$ satisfies the rules of a group.
		\begin{enumerate}
			\item[1.] $\bm{1} = \left[
				\begin{smallmatrix}
					1 & 0 \\ 0 & 1
				\end{smallmatrix}\right]$ is a multiplicative identity element in $\mathrm{SL}_2(\mathbb{Z})$ since $\det(\bm{1}) = 1$.\\ [-10pt]
			\item[2.]  If $\gamma \in \mathrm{SL}_2(\mathbb{Z})$, then $\gamma^{-1}$ exists and is in $\mathrm{SL}_2(\mathbb{Z})$.
			\begin{myIndent}\exTwoP
				To start, we know that the matrix $\gamma^{-1}$ exists because $\det(\gamma) \neq 0$.\\ Also, note that:
				
				{\centering $1 = \det(\bm{1}) = \det(\gamma\gamma^{-1}) = \det(\gamma)\det(\gamma^{-1}) = 1\cdot \det(\gamma^{-1})$\retTwo\par}

				Finally, if $\gamma = \left[
				\begin{smallmatrix}
					a & b \\ c & d
				\end{smallmatrix}\right]$, then we know that $\gamma^{-1} = \frac{1}{\det(\gamma)}\left[
					\begin{smallmatrix}
						d & -b \\ -c & a
					\end{smallmatrix}\right]$. Since $\det(\gamma) = 1$ and $a, b, c, d \in \mathbb{Z}$, this tells us that all the elements of $\gamma^{-1}$ are integers.\retTwo

					We conclude that $\gamma^{-1} \in \mathrm{SL}_2(\mathbb{Z})$.\\ [-10pt]
			\end{myIndent}

			\item[3.] Matrix multiplication is associative on $\mathrm{SL}_2(\mathbb{Z})$ because it's associative on $\mathcal{M}(2, \mathbb{R})$.\retTwo
		\end{enumerate}
	\end{myIndent}

	\item A group homomorphism $\rho: G_1 \longrightarrow G_2$ is said to be \textit{trivial} if $\rho(g) = 1$ for all $g \in G_1$. Otherwise, the homomorphism is said to be \textit{nontrivial}. If $\mathbb{R}$ is the group of real numbers under addition and $\mathbb{R}^{\times}$ is the group of nonzero real numbers under multiplication, then find a non-trivial homomorphism $\rho: \mathbb{R} \longrightarrow \mathbb{R}^{\times}$.

	\begin{myIndent}\exOne
		Given any $\alpha \in \mathbb{R}$ such that $\alpha > 0$, define $\rho(x) = \alpha^x$ for all $x \in \mathbb{R}$. Note that $\rho(x) \neq 0$ for all $x \in \mathbb{R}$, meaing $\rho(x) \in \mathbb{R}^{\times}$ for all $x \in \mathbb{R}$. Then for all $x, y \in \mathbb{R}$, we have that:

		{\centering $\rho(x + y) = \alpha^{x + y} = \alpha^x\alpha^y = \rho(x)\rho(y)$ \retTwo\par}
	\end{myIndent}
\end{enumerate}

\mySepTwo

\mHeader{Homework 2:}


\begin{enumerate}
	\item (Chapter 2, Problem 4.1) Let $a$ and $b$ be elements of a group $G$. Suppose that $a$ has order $7$ and $a^3b = ba^3$. Prove that $ab = ba$.
	
	\begin{myIndent}\exOne
		Since $ba^3 = a^3b$ and $a^7 = 1$, we have that:
		
		{\centering $b = a^3ba^4 = a^3(ba^3)a = a^3(a^3b)a = a^6ba$. \retTwo\par}

		Composing both sides by $a$ on the left, we get that $ab = 1ba = ba$.\retTwo
	\end{myIndent}
	
	\item (Chapter 2, Problem 4.3) Let $a$ and $b$ be elements of a group $G$. Prove that $ab$ and $ba$ have the same order.
	
	\begin{myIndent}\exOne
		Suppose $n$ is the least positive integer for which $(ab)^n = 1$. Then note that\\ $(ba)^k = b(ab)^{k-1}a$ for all $k \in \mathbb{Z}_+$. So, $(ba)^{n+1} = b(ab)^na = ba$, which\\ in turn means $(ba)^n = 1$. Also, from an earlier proposition, we know\\ $(ab)^k = (ab)^{-1} = b^{-1}a^{-1}$ if and only if $k + 1 = n$. So $n$ is the least positive integer for which $(ab)^n = 1$.\retTwo
	\end{myIndent}

	\item (Chapter 2, Problem 4.4) Suppose $G$ is group that contains no proper (nontrivial) subgroup. Prove $G$ is finite and has order $1$ or order $p$ where $p$ is prime.
	
	\begin{myIndent}\exOne
		To start, obviously a trivial group contains no proper subgroup. So, we'll now assume that $\exists x \in G$ such that $x \neq 1$. We know that the cyclic group $\langle x \rangle$ is a nontrivial subgroup of $G$. Therefore, by our assumption about $G$, we know that $\langle x \rangle = G$.\newpage
		
		Suppose $x$ has infinite order. Then we have a contradiction because $\langle x^2 \rangle$ is a subgroup of $\langle x \rangle = G$ which doesn't contain $x \in G$ (by a previous proposition, if $n = 0$ is the only integer for which $x^n = 1$, then $x^k = x^1 \Rightarrow k = 1$).\retTwo

		So, we know $x$ has finite order $p \in \mathbb{Z}_+$. Furthermore, for all $k \in \mathbb{Z}_+$, we know that if $x^k \neq 1$, then by our assumption about $G$ we have that $\langle x^k \rangle = G$  and thus $x^k$ must also have order $p$. But by a previous proposition, we know that $x^k$ has order $\frac{p}{\gcd(p, k)}$. So, $p$ must be coprime with all positive integers less than $p$, meaning that $p$ is prime.\retTwo

		Hence, if $G$ is nontrivial, it must have a prime number of elements.\retTwo
	\end{myIndent}

	\item (Chapter 2, Problem 4.10) Suppose $G$ is a group and $a, b \in G$ have finite order.
	\begin{enumerate}
		\item[(a)] Suppose $G$ is abelian. Then $ab$ has finite order.
		
		\begin{myIndent}\exOne
			Suppose $a$ and $b$ have orders $n$ and $m$ respectively. Then becaues $G$ is abelian:

			{\centering $(ab)^{nm} = a^{nm}b^{nm} = (a^n)^m(b^m)^n = 1^m1^n = 1$ \retTwo\par}

			So, the set of integers $N$ such that $(ab)^N = 1$ contains a nonzero element.\retTwo
		\end{myIndent}

		\item[(b)] Show by example that if $G$ is not abelian, then $ab$ need not have finite order.
		
		\begin{myIndent}\exOne
			Consider the group of bijective functions on $\mathbb{Z}$ with function composition as it's rule of composition. Then consider the bijections on $\mathbb{Z}$:
			
			{\centering $f(n) = -n$ and $g(n) = \left\{
			\begin{matrix}
				n - 1 & \text{ if } n \text{ is even } \\
				n + 1 & \text{ if } n \text{ if odd  }
			\end{matrix}\right.$ \retTwo\par}

			Using multiplicative notation, we clearly have that $f^2(n) = n = g^2(n)$ for all $n \in \mathbb{Z}$. On the other hand, we can  show by induction that $(fg)^N(1) \neq 1$ for all $N \in \mathbb{Z}_+$.

			
			\begin{myIndent}\exTwoP
				Proof:\\ [-20pt]
				\begin{itemize}
					\item If $n$ is odd and positive, then $fg(n) = f(n + 1) = -n - 1$ which is negative, even, and satisfies that $|fg(n)| > |n|$.
					\item If $n$ is even and negative, then $fg(n) = f(n - 1) = -n + 1$ which is positive, odd, and satisfies that $|fg(n)| > |n|$\retTwo
				\end{itemize}

				Since $1$ is a positive odd number, we know that those will be the only two cases we run into when composing $fg$ with itself. It follows that $(fg)^N(1) \neq 1$ for any $N \in \mathbb{Z}_+$ since $|(fg)^N(1)| > 1$ for all $N$.\retTwo
			\end{myIndent}
			
			So, $(fg)$ has infinite order.\newpage
		\end{myIndent}
	\end{enumerate}
	
	\item (Chapter 2, Problem 5.1) Let $\varphi: G \longrightarrow G^\prime$ be a surjective group\\ homomorphism.
	\begin{enumerate}
		\item[(a)] A group is called \udefine{cyclic} if $G = \langle x\rangle$ is generated by a single element $x \in G$. Prove that if $G$ is cyclic, then $G^\prime$ is cyclic.
		
		\begin{myIndent}\exOne
			Suppose $x \in G$ generates $G$, and define $y = \varphi(x)$. Since $\varphi$ is surjective, we know that given any $z \in G^\prime$, there exists $k \in \mathbb{Z}$ with $\varphi(x^k) = z$. So:

			{\centering $z = \varphi(x^k) = (\varphi(x))^k = y^k $ \retTwo\par}

			Thus, $G^\prime$ is cyclic and generated by $y$.\retTwo
		\end{myIndent}

		\item[(b)] Prove that if $G$ is abelian, then $G^\prime$ is abelian. 
		
		\begin{myIndent}\exOne
			Given any $a, b \in G^\prime$, pick $a^\prime, b^\prime \in G$ such that $\varphi(a^\prime) = a$ and $\varphi(b^\prime) = b$.\\ Then $ab = \varphi(a^\prime)\varphi(b^\prime) = \varphi(a^\prime b^\prime) = \varphi(b^\prime a^\prime) = \varphi(b^\prime) \varphi(a^\prime) = ba$.
			\retTwo
		\end{myIndent}
	\end{enumerate}
\end{enumerate}

\mySepTwo

\mHeader{Homework 3:}


\begin{enumerate}
	\item (Chapter 2, Problem 8.3) Suppose $p$ is a prime number and $G$ is a group with order $p^n$ for a positive integer $n$. Prove that $G$ contains an element of order $p$.
	
	\begin{myIndent}\exOne
		Since the order of any element of $G$ must divide $|G|$, we have that if $|G| = p$ where $p$ is prime, then the cyclic group of any non-identity element must have order $p$ as well. Hence, this problem holds true when $n = 1$.\retTwo
		
		Now suppose $|G| = p^N$ and assume the problem holds true for $n < N$. Choose $a$ not equal to $1$ in $G$, and consider the cyclic group $\langle a \rangle$. We know that $|\langle a \rangle|$ must divide $p^N$. And since the only factors of $p^N$ have the form $p^k$ where $k$ is a nonnegative integer at most $N$, we know that $|\langle a \rangle| = p^k$ for some integer $0 \leq k \leq N$.\retTwo
		
		If $k < N$, then we can apply our inductive hypothesis to say that there is an element of order $p$ in $\langle a \rangle$ and thus in $G$.\retTwo

		f $k = N$, then consider the cyclic group $\langle a^{(p^{N-1})} \rangle$ Note that\\ $(a^{(p^{N-1})})^p = a^{(p^N)} = 1$. Also, for any integer $k \in \{1, \ldots, p-1\}$, we\\ know that $0 < kp^{N-1} < p^N$, meaning $(p^{N-1})^k - 0$ is not a multiple of\\ $p^N$. So, $a^{(p^{N-1})} \in G$ has order $p$.\newpage
	\end{myIndent}

	\item (Chapter 2, Problem 8.5) Suppose $G$ is a finite group and that $G$ contains an element of order 10 and an element of order 6. Prove that $|G|$ is a multiple of $30$.
	
	\begin{myIndent}\exOne
		Since the order of any element of $G$ must divide $|G|$, we know that both $10$ and $6$ must divide $|G|$. Importantly, letting $m = \lcm(6, 10)$, we know from a proposition in class that for any $n$ satisfying that $10 \divides n$ and $6 \divides n$, we know that $m \divides n$. So $m$ must divide $|G|$. And it just so happens that $m = \lcm(6, 10) = 30$.
		\retTwo
	\end{myIndent}
	
	\item (Chapter 2, Problem 8.6) Suppose $\varphi: G \longrightarrow G^\prime$ is a group homomorphism, $|G| = 18$ and $|G^\prime| = 15$. Assume that $\varphi$ is not the trivial homomorphism. What is the order of $\ker(\varphi)$.
	
	\begin{myIndent}\exOne
		We know that $|\ker(\varphi)|\cdot|\im(\varphi)| = |G^\prime|$, and that $|\im(\varphi)| \neq 1$. As a result we know one of the following cases is true:
		\begin{itemize}
			\item $|\ker(\varphi)| = 1$ and $|\im(\varphi)| = 18$
			\item $|\ker(\varphi)| = 2$ and $|\im(\varphi)| = 9$
			\item $|\ker(\varphi)| = 3$ and $|\im(\varphi)| = 6$
			\item $|\ker(\varphi)| = 6$ and $|\im(\varphi)| = 3$
			\item $|\ker(\varphi)| = 9$ and $|\im(\varphi)| = 2$\retTwo
		\end{itemize}
		
		But then note that taking into account that $|G^\prime| = 16$, there is only one option above that satisfies that $|\im(\varphi)|$ divides $16$. Hence, we know that:

		{\center $|\ker(\varphi)| = 9$ and $|\im(\varphi)| = 2$ \retTwo\par}
	\end{myIndent}
	
	\item (Chapter 2, Problem 8.10) Suppose $G$ is a group and $N$ is a subgroup of $G$ of index $2$. Prove that $N$ is normal.
	
	\begin{myIndent}\exOne
		Note that since $[G:N] = 2$ and $N = 1N$ is a coset of $N$, we know that the other coset must be $G \setminus N$.\retTwo

		Now I'm running out of time and thus didn't have time to show this. But to be fully accurate, since we defined the index of a group to be based on the number of left cosets, we need to show that there are the same number of right and left cosets. At least if $G$ is finite, then this is trivial (because all the reasoning we've done in class could just as easily have been done using right-cosets)\retTwo

		So assuming that $[G:N]$ also gives the number of right cosets, then note that as before, we have that the right cosets of $G$ are $N$ and $G \setminus N$. So, every left coset of $N$ is a right coset of $N$ and vice versa. It follows that $N$ is normal.
		\newpage
	\end{myIndent}
\end{enumerate}

\mHeader{Homework 4:}


\begin{enumerate}
	\item Suppose $r_1, \ldots, r_n$ are positive integers. Say that the $r_j$ are \udefine{pairwise coprime}\\ if $\gcd(r_i, r_j) = 1$ for all $i \neq j$. Prove the following generalization of the\\ Chinese Remainder Theorem: Assume the positive integers $r_1, \ldots, r_n$ are\\ pairwise coprime. Then the canonical map:
	
	{\centering $\mathbb{Z} / (r_1\cdots r_n)\mathbb{Z} \longrightarrow (\mathbb{Z} / r_1\mathbb{Z}) \times \cdots \times (\mathbb{Z} / r_n\mathbb{Z})$\par}

	given by $a + r_1\cdots r_n\mathbb{Z} \mapsto (a + r_1\mathbb{Z}, \ldots, a + r_n\mathbb{Z})$ is an isomorphism.

	\begin{myIndent}\exOne
		We already proved the case where $n = 2$ in class. So, let's now proceed by induction.\retTwo

		Firstly, observe that if $r_n$ is coprime with $r_1, \ldots, r_{n-1}$, then we have that $r_n$ is coprime with $r_1 \cdots r_{n-1}$. To see this, assume for the sake of contradiction that there exists $d \neq 1$ which divides both $r_n$ and $r_1, \ldots, r_{n-1}$. Since $r_n$ and $r_1$ are coprime, we know that $d \not\divides r_1$. Thus, $d \divides r_1 (r_2\cdots r_{n-1}) \Longrightarrow d \divides r_2 \cdots r_{n-1}$.\\ Repeating this reasoning, we will eventually get that $d \divides r_{n-1}$. This contradicts that $r_{n-1}$ and $r_n$ are coprime.\retTwo

		Thus, using the Chinese Remainder theorem, we know the canonical map\\ $a + r_1\cdots r_{n}\mathbb{Z} \mapsto (a + r_1\cdots r_{n-1}\mathbb{Z}, a + r_n\mathbb{Z})$ is an isomorphism.\retTwo

		By induction, we can say that the canonical map\\ $a + r_1\cdots r_{n-1}\mathbb{Z} \mapsto (a + r_1\mathbb{Z}, \ldots, a + r_{n-1}\mathbb{Z})$ is an isomorphism.\retTwo
		
		It follows that the map below is an isomorphism:

		{\centering $(a + r_1\cdots r_{n-1}\mathbb{Z}, a + r_n\mathbb{Z}) \mapsto (a + r_1\mathbb{Z}, \ldots, a + r_{n-1}\mathbb{Z}, a + r_n\mathbb{Z})$ \retTwo\par}

		And finally, since the composition of two group isomorphisms is itself a group isomorphism, we thus know that the map given by the problem is an\\ isomorphism.\retTwo
	\end{myIndent}

	\item Suppose $p$ is a prime number. Prove \udefine{Wilson's Theorem}: $(p - 1)! \equiv -1 \mMod{p}$.
	
	\begin{myIndent}\exOne
		Consider that if $a^2 \equiv 1 \mMod{p}$, then we must have that\\ $a^2 - 1 = (a + 1)(a - 1) \equiv 0 \mMod{p}$. As a result, we know that $p$ divides either $(a + 1)$ or $(a - 1)$. In the first case, we'd have that $a \equiv p - 1 \mMod{p}$. In the other case, we'd have that $a \equiv 1 \mMod{p}$.\retTwo

		Now if $p = 2$, then the theorem is true because $(p - 1)! = 1 \equiv -1 \mMod{2}$. So, we can now assume that $p - 1 \not\equiv 1 \mMod{p}$. Then note that\\ $(p - 1)! = (p-1)(p-2)\cdots(2) \equiv -1\cdot(p-2)\cdots(2)$.\newpage

		Now $(p-2)\cdots(2)$ consists of $p - 3$ terms distinct from $1$ and $p - 1$. This is importantly an even number of terms. Also, each term  will be the unique inverse of precisely one other term in that expansion because we've already shown that none of those terms are their own inverses. Hence, we can replace half of them with the inverses of the other half. And since $(\mathbb{Z} / p\mathbb{Z})^\times$ is abelian, we can rearrange terms to show their product is equivalent to $1$ modulo $p$.\retTwo
		
		Thus, we conclude that $(p - 1)! \equiv -1\cdot(p-2)\cdots(2) \equiv -1$.\retTwo
	\end{myIndent}

	\item Suppose $n$ is an integer and $n \equiv 3 \mMod{4}$. Prove that there does not exist integers $x, y$ with $x^2 + y^2 = n$.
	
	\begin{myIndent}\exOne
		To see why this is, consider the table below where each entry gives the equivalence class of $x^2 + y^2$ modulo $4$ depending on the equivalence class of $x$ and $y$ module $4$.
		
		{\center\begin{tabular}{c | c c c c}
			& $x \equiv 0$ & $x \equiv 1$ & $x \equiv 2$ & $x \equiv 3$ \\\hline \\ [-12pt]
			$y \equiv 0$ & $0$ & $1$ & $0$ & $1$ \\
			$y \equiv 1$ & $1$ & $2$ & $1$ & $2$ \\
			$y \equiv 2$ & $0$ & $1$ & $0$ & $1$ \\
			$y \equiv 3$ & $1$ & $2$ & $1$ & $2$
		\end{tabular}\retTwo\par}

		Notice that in none of the above entries do we have that $x^2 + y^2 \equiv 3 \mMod{4}$. Thus, given any integers $x$ and $y$, it is impossible for $x^2 + y^2$ to be in the set\\ $3 + 4\mathbb{Z}$ which contains $n$.\retTwo
	\end{myIndent}

	\item Suppose $p$ is a prime number and $p \equiv 1 \mMod{4}$. Then there exists $x \in \mathbb{Z}$ with $x^2 + 1 \equiv 0 \mMod{p}$.
	
	\begin{myIndent}\exOne
		By Wilson's theorem, we know that $(p - 1)(p - 2)\ldots (2)(1) \equiv -1 \mMod{p}$. We can rewrite this as follows:

		{\centering
		\begin{tabular}{r l}
			& $(p-1)(p-2)\ldots(\frac{p+1}{2})(\frac{p-1}{2})\ldots(2)(1) \equiv -1$ \\ [4pt]
			$\Longrightarrow$ & $(-1)(-2)\ldots(-\frac{p-1}{2})(\frac{p-1}{2})\ldots(2)(1) \equiv -1$ \\ [4pt]
			$ \Longrightarrow $ & $(-1)^{\frac{p-1}{2}}((\frac{p-1}{2})!)^2 \equiv -1$
		\end{tabular}\retTwo\par}

		
		\begin{myIndent}\exPP
			We know that $p + 1 \equiv -p + 1 = -(p - 1) \mMod{p}$. And since $2$ has a unique inverse in $\mathbb{Z} / p\mathbb{Z}$, we can thus say that $\frac{p+1}{2} \equiv -\frac{p-1}{2} \mMod{p}$.\retTwo
		\end{myIndent}

		Since $p \equiv 1 \mMod{4}$, we know that $p - 1$ is a multiple of $4$. It follows that\\ $\frac{p-1}{2}$ is a multiple of $2$. Thus $(-1)^{\frac{p-1}{2}} = 1$. And hence, $((\frac{p-1}{2})!)^2 \equiv -1 \mMod{p}$. Setting $x = (\frac{p-1}{2})!$, we thus have that $x^2 + 1 \equiv 0 \mMod{p}$.

		\retTwo
	\end{myIndent}
\end{enumerate}

\newpage

\mHeader{Homework 6:}

\begin{enumerate}
	\item Prove that $\mathrm{GL}_2(\mathbb{R})$ acts transitively on $S \coloneq \mathbb{R}^2 - \{(0, 0)\}$.
	
	\begin{myIndent}\exOne
		Let $s \coloneq (1, 0) \in S$. Then given any $x = (a, c) \in S$ (meaning we don't have that $a = b = 0$), first pick $y = (b, d) \neq (0, 0)$ such that $y$ is not a scalar multiple of $x$. Then set $g = \left(
		\begin{smallmatrix}
			a & b \\ c & d
		\end{smallmatrix}\right)$. Note that $\det(g) \neq 0$, meaning $g \in \mathrm{GL}_2(\mathbb{R})$. Also $g(s) = x$.\retTwo

		Thus, we've shown that all $x \in S$ are in the orbit of $s$. So $\mathrm{GL}_2(\mathbb{R})$ acts\\ transitively on $S$ since it has only one orbit in $S$.\retTwo
	\end{myIndent}

	\item Defining $S$ as before, what is the stabilizer of the vector $(0, 1)$ for the action of $\mathrm{GL}_2(\mathbb{R})$ on $S$?
	
	\begin{myIndent}\exOne
		The stabilizer of $(0, 1)$ will be the set of all matrices $\left(
		\begin{smallmatrix}
			a & 0 \\ c & 1
		\end{smallmatrix}\right)$ which are invertible (i.e. in $\mathrm{GL}_2(\mathbb{R})$). The reason why is that $\left(
		\begin{smallmatrix}
			a & b \\ c & d
		\end{smallmatrix}\right)\left(
		\begin{smallmatrix}
			0 \\ 1
		\end{smallmatrix}\right) = \left(
			\begin{smallmatrix}
				b \\ d
			\end{smallmatrix}\right)$. So an element in the stabilizer must have $b = 0$ and $d = 1$.\retTwo

		Now note that $\left(
		\begin{smallmatrix}
			a & 0 \\ c & 1
		\end{smallmatrix}\right)$ is triangular and thus invertible so long as $a \neq 0$. Hence, the stabilizer of $(0, 1)$ is the set $\{\left(\begin{smallmatrix}
			a & 0 \\ c & 1
		\end{smallmatrix}\right) | a, c \in \mathbb{R}, a \neq 0 \}$.
		\retTwo
	\end{myIndent}

	\item Suppose $z = x + iy \in \mathbb{C}$ with $y > 0$, and $g = \left(
	\begin{smallmatrix}
		a & b \\ c & d
	\end{smallmatrix}\right) \in \mathrm{SL}_2(\mathbb{R})$.
	\begin{enumerate}
		\item[(a)] Check that $cz + d \neq 0$.
		
		\begin{myIndent}\exOne
			Note that $cz + d = (cx + d) + i(cy)$ since $c$ and $d$ are real. Thus if $cz + d = 0$, we must have that $cy = 0$, meaning that $c = 0$ since $y \neq 0$. But then $cz + d = 0 \Rightarrow d = 0$. So $c = 0 = d$. But this implies that $\det\left(
				\begin{smallmatrix}
					a & b \\ c & d
				\end{smallmatrix}\right) = 0$, contradicting that $\left(
					\begin{smallmatrix}
						a & b \\ c & d
					\end{smallmatrix}\right) \in \mathrm{SL}_2(\mathbb{R})$.
			\retTwo
		\end{myIndent}

		\item[(b)] Let $g \cdot z = \frac{az+b}{cz+d}$ which is defined because $cz + d \neq 0$. Prove that\\ $\ima(g \cdot z) = \frac{y}{|cz + d|^2}$.
		\begin{myIndent}\exOne
			Observe:

			{\centering $\frac{az + b}{cz + d} = \frac{(az + b)(c\overline{z} + d)}{|cz + d|^2} = \frac{(acx^2 + acy^2 + adx + bcx + bd) + i((ad-bc)y)}{|cz + d|^2}$\retTwo\par}

			Now $ad - bc = \det\left(
				\begin{smallmatrix}
					a & b \\ c & d
				\end{smallmatrix}\right) = 1$ by assumption. So $i\frac{(ad-bc)y}{|cz + d|^2} = i\frac{y}{|cz + d|^2}$.\retTwo

			Also note that because $y > 0$ and $|cz + d|^2 > 0$, we know that\\ $\ima(\frac{az + b}{cz + d}) = \frac{y}{|cz + d|^2} > 0$.
			\retTwo
		\end{myIndent}
		\item[(c)] Let $\mathcal{H} = \{z \in \mathbb{C} \mid \ima(z) > 0\}$. If $g \in \mathrm{SL}_2(\mathbb{R})$ and $z \in \mathcal{H}$, the previous part shows $g \cdot z \in \mathcal{H}$. Prove that $(g, z) \mapsto g \cdot z$ gives an action of $\mathrm{SL}_2(\mathbb{R})$ on $\mathcal{H}$.  
		\begin{myIndent}\exOne
			Firstly, $\left(
			\begin{smallmatrix}
				1 & 0 \\ 0 & 1
			\end{smallmatrix}\right) \cdot z = \frac{1z + 0}{0z + 1} = z$.
			\newpage
			Secondly, let $g = \left(
			\begin{smallmatrix}
				a & b \\ c & d
			\end{smallmatrix}\right)$ and $h = \left(
				\begin{smallmatrix}
					a^\prime & b^\prime \\ c^\prime & d^\prime
			\end{smallmatrix}\right)$. Then note that $gh = \left(
				\begin{smallmatrix}
					aa^\prime + bc^\prime & ab^\prime + bd^\prime \\ ca^\prime + dc^\prime & cb^\prime + dd^\prime
			\end{smallmatrix}\right)$.\retTwo

			So:
			\begin{itemize}
				\item $gh \cdot z = \frac{(aa^\prime + bc^\prime)z + ab^\prime + bd^\prime }{(ca^\prime + dc^\prime)z + cb^\prime + dd^\prime}$.
				
				\item $g \cdot (h \cdot z) = g \cdot \frac{a^\prime z + b^\prime}{c^\prime z + d^\prime} = \frac{a\frac{a^\prime z + b^\prime}{c^\prime z + d^\prime} + b}{c\frac{a^\prime z + b^\prime}{c^\prime z + d^\prime} + d} = \frac{aa^\prime z + ab^\prime + bc^\prime z + bd^\prime}{ca^\prime z + cb^\prime + dc^\prime z + dd^\prime} = \frac{(aa^\prime + bc^\prime)z + ab^\prime + bd^\prime }{(ca^\prime + dc^\prime)z + cb^\prime + dd^\prime}$.
			\end{itemize}
			\retTwo
		\end{myIndent}
	\end{enumerate}

	\item Let $K = \mathrm{SO}(2) \subseteq \mathrm{SL}_2(\mathbb{R})$ and let $B \subseteq \mathrm{SL}_2(\mathbb{R})$ be the subgroup of upper triangular matrices.
	
	\begin{enumerate}
		\item[(a)] Defining $\mathcal{H}$ as before, prove that $B$ acts transitively on $\mathcal{H}$ and consequently so does $\mathrm{SL}_2(\mathbb{R})$.
		
		\begin{myIndent}\exOne
			To start, if $g \in B$ if and only if $g = \left(
			\begin{smallmatrix}
				a & b \\ 0 & \sfrac{1}{a}
			\end{smallmatrix}\right)$ where $a, b \in \mathbb{R}$ with $a \neq 0$. This is because the matrix must be upper triangular and $\det \left(
				\begin{smallmatrix}
					a & b \\ 0 & d
				\end{smallmatrix}\right) = ad = 1$ implies $d = \frac{1}{a}$.\retTwo

			Now let $z = x + iy \in \mathcal{H}$. Since $y > 0$, we can set $a = \sqrt{y} \neq 0$. Then set $b = \sfrac{x}{a}$. Having done that, note that $\left(\begin{smallmatrix}
				a & b \\ 0 & \sfrac{1}{a}
			\end{smallmatrix}\right) \in B$ with:
			
			{\centering$\left(\begin{smallmatrix}
				a & b \\ 0 & \sfrac{1}{a}
			\end{smallmatrix}\right) \cdot i = \frac{ai + b}{\sfrac{1}{a}} = a^2 i + ab = yi + x = z$.\retTwo\par}

			Since $z$ was arbitrary, the orbit of $i$ under $B$ is all of $\mathcal{H}$. So, there is only one orbit, meaning $B$ acts transitively on $\mathcal{H}$. Since $b \subseteq \mathrm{SL}_2(\mathbb{R})$, this also means that $\mathrm{SL}_2(\mathbb{R})$ acts transitively on $\mathcal{H}$.\retTwo
		\end{myIndent}

		\item[(b)] Prove that the stabilizer of $i \in \mathcal{H}$ is $\mathrm{SO}(2)$.
		
		
		\begin{myIndent}\exOne
			Consider that for $g = \left(\begin{smallmatrix}
				a & b \\ c & d
			\end{smallmatrix}\right)  \in \mathrm{SL}_2(\mathbb{R})$, we have that:

			{\centering $g \cdot i = \frac{ai + b}{ci + d} = \frac{(ai + b)(d - ci)}{c^2 + d^2} = \frac{ac+bd}{c^2 + d^2} + i\frac{ad - bc}{c^2 + d^2} = \frac{ac+bd}{c^2 + d^2} + i\frac{1}{c^2 + d^2}$ \retTwo\par}

			Thus if $g \cdot i = i$, we must have that $c^2 + d^2 = 1$ and $ac + bd = 0$.\retTwo

			Now if $g$ is also orthogonal, then we know by definition that:
			
			{\centering $gg^T = \left(\begin{smallmatrix}
				a & b \\ c & d
			\end{smallmatrix}\right)\left(\begin{smallmatrix}
				a & c \\ b & d
			\end{smallmatrix}\right) = \left(\begin{smallmatrix}
				a^2 + b^2 & ac + bd \\ ac + bd & c^2 + d^2
			\end{smallmatrix}\right) = \left(\begin{smallmatrix}
				1 & 0 \\ 0 & 1
			\end{smallmatrix}\right)$\retTwo\par}

			So it's clear that $g$ being orthogonal means that $g \cdot i = i$. On the other hand, suppose $g \cdot i = i$, meaning $c^2 + d^2 = 1$ and $ac + bd = 0$.\retTwo
			
			Note that the stabilizer of $i$ is a subgroup of $\mathrm{SL}_2(\mathbb{R})$. Thus we know that $g^{-1} = \frac{1}{ad-bc}\left(
			\begin{smallmatrix}
				d & -b \\ -c & a
			\end{smallmatrix}\right) = \left(
				\begin{smallmatrix}
					d & -b \\ -c & a
				\end{smallmatrix}\right)$ also satisfies that $g^{-1} \cdot i = i$. This tells us that we also must have that $c^2 + a^2 = 1$ and $ab + cd = 0$.\newpage

				Note that $ac + bd = 0 \Longrightarrow (1 - c^2)c^2 = a^2c^2 = b^2d^2 = b^2(1 - c^2)$.
				
				\begin{myIndent}\exTwoP
					Case 1: $c^2 = 1$
					\begin{myIndent}
						Then $a^2 = d^2 = 0$, meaning $a = d = 0$. Hence, our equation $ad - bc = 1$ reduces to $b = \frac{-1}{c}$, meaning $b^2 = \frac{1}{c^2} = 1$ and $a^2 + b^2 = 0 + 1 = 1$.\retTwo
					\end{myIndent}

					Case 2: $c^2 \neq 1$
					\begin{myIndent}
						Then we've shown that $(1 - c^2)c^2 = b^2(1 - c^2) \Longrightarrow b^2 = c^2 \Longrightarrow b = \pm c$. As a result, $a^2 + b^2 = a^2 + (c)^2 = 1$.\retTwo
					\end{myIndent}
				\end{myIndent} 

				Thus we've shown that $a^2 + b^2 = 1$. This combined with the fact that $c^2 + d^2 = 1$ and $ac + bd = 0$ means that $gg^T = \left(
				\begin{smallmatrix}
					1 & 0 \\ 0 & 1
				\end{smallmatrix}\right)$. So $g$ is orthogonal.\retTwo

				We've thus shown that the stabilizer of $i$ is $\mathrm{O}(2) \cap \mathrm{SL}_2(\mathbb{R}) = \mathrm{OS}(2)$.
			\retTwo
		\end{myIndent}

		\item[(c)] Deduce that if $g \in \mathrm{SL}_2(\mathbb{R})$, there exists $b \in B$ and $k \in \mathrm{SO}(2)$ so that\\ $g = bk$.
		
		\begin{myIndent}\exOne
			Let $g \in \mathrm{SL}_2(\mathbb{R})$. By part (a), we can find $b \in B$ such that $g \cdot i = b \cdot i$. Thus, we know that $b^{-1}g$ must be in the stabilizer of $i$: $\mathrm{SO}(2)$. So, set $k = b^{-1}g$. Then $b \in B$, $k \in K$, and $bk = bb^{-1}g = g$.
		\end{myIndent}
	\end{enumerate}
\end{enumerate}

\mySepTwo

\mHeader{Homework 8:} 

\blab{Problem 1}: Suppose $X, Y \in M_n(\mathbb{C})$ are $n\times n$ matrices and $S \in \mathrm{GL}_n(\mathbb{C})$.

\begin{enumerate}
	\item[(a)] Prove that $\tr(XY) = \tr(YX)$.
	\begin{myIndent}\exOne
		Proof: $\tr(XY) = \sum\limits_{i=1}^{n}\left(\sum\limits_{j=1}^n x_{i,j}y_{j,i}\right) = \sum\limits_{j=1}^{n}\left(\sum\limits_{i=1}^n y_{j,i}x_{i,j}\right) = \tr(YX)$\retTwo 

	\end{myIndent}
	\item[(b)] Deduce that $\tr(SXS^{-1}) = \tr(X)$. 
	\begin{myIndent}\exOne
		Because of part (a), we have that $\tr(SXS^{-1}) = \tr((SX)S^{-1}) = \tr(S^{-1}(SX)) = \tr(S^{-1}SX) = \tr(X)$.
		\retTwo
	\end{myIndent}
\end{enumerate}

\blab{Problem 2}: Suppose $G$ Is a finite group, $V$ is a finite dimensional $\mathbb{C}$ vector space, and $\rho: G \longrightarrow \mathrm{GL}(V)$ is a representation. For $v \in V$, define:

{\centering $\mathbb{C}[G](v) = \Span_{g \in G}\{g \cdot v\} \coloneq \left\{\sum\limits_{g \in G}a_g \rho(g)(v) \colon a_g \in \mathbb{C}\right\}$ \retTwo\par}

Prove that $V$ is irreducible iff $\mathbb{C}[G](v) = V$ for all $v \neq 0$ in $V$.\newpage


\begin{myIndent}\exOne
	($\Longleftarrow$)\\
	Suppose $W$ is a nontrivial (i.e. $\neq \{0\}$) $G$-invariant subspace of $V$. Then pick $v \neq 0$ in $W$. Since $W$ is $G$-invariant, we know that $\rho(g)(y) \in W$ for all $g \in G$. Since $W$ is a subspace, it follows that $\mathbb{C}[G](v) \subseteq W \subseteq V$. But by hypothesis, $\mathbb{C}[G](v) = V$. So the only $G$-invariant subspaces of $V$ are $V$ and $\{0\}$.\retTwo

	($\Longrightarrow$)\\
	Fix $v$ in $V$. We claim that $\mathbb{C}[G](v)$ is a $G$-invariant subspace of $V$.
	\begin{myIndent}\exTwoP
		If $v = 0$, then because $\rho(g)(v) = 0$ for all $g \in G$, we have that\\ $\Span_{g \in G}\{g \cdot v\} = \{0\}$ and that is trivially irreducible.\retTwo

		If $v \neq 0$, then let $g^\prime \in G$ and $v^\prime \in \mathbb{C}[G](v) = \Span_{g \in G}\{g \cdot v\}$, meaning there\\ [2pt] exists $a_g \in \mathbb{C}$ for all $g \in G$ such that $v^\prime = \sum\limits_{g \in G} a_g \rho(g)(v)$. But note:

		{\centering
		\begin{tabular}{l}
			$\rho(g^\prime)(v^\prime) = \rho(g^\prime)(\sum\limits_{g \in G} a_g \rho(g)(v)) = \sum\limits_{g \in G} a_g \rho(g^\prime)(\rho(g)(v))$\\ [14pt]

			$\phantom{\rho(g^\prime)(v^\prime) = \rho(g^\prime)(\sum\limits_{g \in G} a_g \rho(g)(v))} = \sum\limits_{g \in G} a_g \rho(g^\prime g)(v) = \sum\limits_{h \in G} a_{(g^\prime)^{-1}h}\rho(h)(v)$
		\end{tabular} \retTwo\par}

		So $\rho(g^\prime)(v^\prime) \in \Span_{g \in G}\{g \cdot v\} = \mathbb{C}[G](v)$. And since $v^\prime$ and $g^\prime$ were arbitrary,\\ [2pt] we've shown that $\mathbb{C}[G](v)$ is $G$-invariant.\retTwo
	\end{myIndent}

	It follows that if $V$ is irreducible, we must that $\mathbb{C}[G](v) = \{0\}$ or $V$ for all $v \in V$. If $v \neq 0$, then the former cannot be the case since $v = 1\rho(1_G)(v) \in \mathbb{C}[G](v)$. So, $\mathbb{C}[G](v) = V$ for all $v \in V - \{0\}$.\retTwo
\end{myIndent}

\blab{Problem 3}: The standard representation of the symmetric group $S_n$ is defined as follows: Let $S_n$ act on $\mathbb{C}^n$ by permutations, $\sigma(v_1, \ldots, v_n) = (v_{\sigma^{-1}(1)}, \ldots, v_{\sigma^{-1}(n)})$. Set $W \subseteq \mathbb{C}^n$ to be the subspace of elements whose coordinates sum to $0$ so that $W$ is $n-1$ dimensional. We let $S_n$ act on $W$ by the restriction of the $S_n$ action on $\mathbb{C}^n$.\retTwo

Prove that this is irreducible.

\begin{myIndent}\exOne
	To start, we know that $W$ is $S_n$-invariant because if $v_1 + \ldots + v_n = 0$, then so does $v_{\sigma^{-1}(1)} + \ldots + v_{\sigma^{-1}(n)} = 0$. In turn, this means that $\mathbb{C}[S_n](v) \subseteq W$ for all $v \in W$ since $W$ is a subspace and $\sigma \cdot v \in W$ for all $\sigma \in S_n$.\retTwo

	Suppose $w = (w_1, \ldots, w_n) \in W$ is not zero. Then there exists $i,j \in \{1, \ldots, n\}$ with $i \neq j$ so that $w_i \neq w_j$. Let $\tau$ be the permutation of $S_n$ that exchanges $i$ and $j$ and leaves the rest of the indices fixed. Then letting $\alpha = (w_j - w_i) \neq 0$ and $e_k$ be the $k$th standard basis vector of $\mathbb{C}^n$, we have:
	
	{\centering $(\tau \cdot w) - w = (0, \ldots, w_j - w_i, \ldots, w_i - w_j, \ldots, 0) = \alpha(e_i - e_j)$.\retTwo\par}

	Now $e_i - e_j \in W$ and so similar to before, we know that $\mathbb{C}[S_n](e_i - e_j) \subseteq W$. At the same time, we know that $W$ is spanned by the set of vectors $\{e_1 - e_k \colon 2 \leq k \leq n\}$. If $k \neq j$, then letting $\sigma \in S_n$ have the cycles $(j, k)$ and $(1, i)$, we have that $\sigma \cdot (e_i - e_j) = e_1 - e_k$. Meanwhile, if $i = k$, then letting $\sigma \in S_n$ have the cycle the $(j, i, 1)$ we then have that $\sigma \cdot (e_i - e_j) = e_1 - e_i$.\newpage

	So $W = \Span\{e_1 - e_k \colon 2 \leq k \leq n\} \subseteq \Span_{g \in G}\{g \cdot (e_i - e_j)\} \subseteq W$. Hence, $\mathbb{C}[S_n](e_i - e_j) = W$.\retTwo

	Now, note that for $v \in \mathbb{C}[S_n](e_i - e_j) = W$:

	{\center
	\begin{tabular}{l}
		$v = \sum\limits_{\sigma \in S_n} a_{\sigma}(\sigma \cdot (e_i - e_j)) = \sum\limits_{\sigma \in S_n} \frac{a_{\sigma}}{\alpha}(\sigma \cdot (\tau \cdot w - w))$\\ [14pt]

		$\phantom{v = \sum\limits_{\sigma \in S_n} a_{\sigma}(\sigma \cdot (e_i - e_j))} = \sum\limits_{\sigma \in S_n} \frac{a_{\sigma}}{\alpha}(\sigma \cdot (\tau \cdot w) - \sigma \cdot w)$\\ [14pt]

		$\phantom{v = \sum\limits_{\sigma \in S_n} a_{\sigma}(\sigma \cdot (e_i - e_j))} = \sum\limits_{\sigma \in S_n} \frac{a_{\sigma}}{\alpha}(\sigma\tau \cdot w - \sigma \cdot w)$\\ [14pt]

		$\phantom{v = \sum\limits_{\sigma \in S_n} a_{\sigma}(\sigma \cdot (e_i - e_j))} = \sum\limits_{\sigma \in S_n} \left(\frac{a_{(\sigma\tau)}}{\alpha} - \frac{a_\sigma}{\alpha}\right)\sigma \cdot w \in \Span_{g \in G}\{g \cdot w\} = \mathbb{C}[S_n](w)$
	\end{tabular} \retTwo\par}

	Hence $W \subseteq \mathbb{C}[S_n](w)$. And from before we know that $\mathbb{C}[S_n](w) \subseteq W$.\\ So $\mathbb{C}[S_n](w) = W$. By the conclusion of problem 2, this shows that $W$ is irreducible.






\end{myIndent}



\newpage

\exOne Our textbook is \textit{Algebra, Second Edition} by Michael Artin.




\end{document}