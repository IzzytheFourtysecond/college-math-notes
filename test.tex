\documentclass{book}

\usepackage{fontspec} % used to import Calibri
\usepackage{anyfontsize} % used to adjust font size

% needed for inch and other length measurements
% to be recognized
\usepackage{calc}

% for colors and text effects as is hopefully obvious
\usepackage[dvipsnames]{xcolor}
\usepackage{soul}

% control over margins
\usepackage[margin=1in]{geometry}
\usepackage[strict]{changepage}

\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{bm}

\usepackage[scr=rsfso, scrscaled=.96]{mathalpha}

% This is how I'm getting the nice caligraphy font :(
\DeclareMathAlphabet{\eulerscr}{U}{eus}{m}{n}
\newcommand{\mathcalli}[1]{\text{\scalebox{1.11}{$\eulerscr{#1}$}}}


\usepackage{amssymb} % originally imported to get the proof square
\usepackage{xfrac}
\usepackage[overcommands]{overarrows} % Get my preferred vector arrows...
\usepackage{relsize}

% Just am using this to get a dashed line in a table...
% Also you apparently want this to be inactive if you aren't
% using it because it slows compilation.
\usepackage{arydshln} \ADLinactivate 
\newenvironment{allowTableDashes}{\ADLactivate}{\ADLinactivate}

\usepackage{graphicx}
\graphicspath{{./158_Images/}}

\usepackage{tikz}
   \usetikzlibrary{arrows.meta}
   \usetikzlibrary{graphs, graphs.standard}

\usepackage{quiver} %commutative diagrams






\usepackage[hidelinks]{hyperref}
\newcommand{\inLinkRap}[2]{{\color{blue}\hyperlink{#1}{\textit{#2}}}}







\newfontfamily{\calibri}{Calibri}
\setlength{\parindent}{0pt}
\definecolor{RawerSienna}{HTML}{945D27}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%Arrow Commands:

% Thank you Bernard, gernot, and Sigur who I copied this from:
% https://tex.stackexchange.com/questions/364096/command-for-longhookrightarrow
\renewcommand{\hookrightarrow}{\lhook\joinrel\rightarrow}
\renewcommand{\hookleftarrow}{\leftarrow\joinrel\rhook}
\newcommand{\hooklongrightarrow}{\lhook\joinrel\longrightarrow}
\newcommand{\hooklongleftarrow}{\longleftarrow\joinrel\rhook}
\newcommand{\hookxlongrightarrow}[2][]{\lhook\joinrel\xrightarrow[#1]{#2}}
\newcommand{\hookxlongleftarrow}[2][]{\xleftarrow[#1]{#2}\joinrel\rhook}

% Thank you egreg who I copied from:
% https://tex.stackexchange.com/questions/260554/two-headed-version-of-xrightarrow
\newcommand{\longrightarrowdbl}{\longrightarrow\mathrel{\mkern-14mu}\rightarrow}
\newcommand{\rightarrowdbl}{\rightarrow\mathrel{\mkern-14mu}\rightarrow}
\newcommand{\longleftarrowdbl}{\leftarrow\mathrel{\mkern-14mu}\longleftarrow}

\newcommand{\xrightarrowdbl}[2][]{%
  \xrightarrow[#1]{#2}\mathrel{\mkern-14mu}\rightarrow
}
\newcommand{\xleftarrowdbl}[2][]{%
  \leftarrow\mathrel{\mkern-14mu}\xleftarrow[#1]{#2}
}

\newcommand{\mRoman}[1]{%
   \textrm{\MakeUppercase{\romannumeral #1}}%
}



% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\newcommand{\hOne}{%
   \color{Black}%
   \fontsize{14}{16}\selectfont%
}
\newcommand{\hTwo}{%
\color{Black}%
   \fontsize{13}{15}\selectfont%
}
% \newcommand{\scratchWork}{%
%    \color{PineGreen!85!Orange}
%    \fontsize{12}{14}\selectfont%
% }
\newcommand{\hThree}{%
   \color{Black}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\myComment}{%
   \color{RawerSienna}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\pracOne}{
   \color{BrickRed}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\pracTwo}{
   \color{Orange}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\why}{%
   \color{Orange}%
   \fontsize{12}{14}\selectfont%
	Why:
}
\newcommand{\exOne}{%
   \color{Purple}%
   \fontsize{14}{16}\selectfont%
}
\newcommand{\exTwo}{%
   \color{Purple}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\exThree}{%
   \color{Purple}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\exP}{%
   \color{Purple}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\exTwoP}{%
   \color{RedViolet}%
   \fontsize{13}{15}\selectfont%
}
\newcommand{\exThreeP}{%
   \color{RedViolet}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\exFourP}{%
   \color{RedViolet}%
   \fontsize{11}{13}\selectfont%
}
\newcommand{\exPP}{%
   \color{RedViolet}%
   \fontsize{12}{14}\selectfont%
}
\newcommand{\exPPP}{%
   \color{VioletRed}%
   \fontsize{12}{14}\selectfont%
}

% Homework standard below (God the bloat in the header is absurd...)
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\newcommand{\Hstatement}{%
   \color{MidnightBlue!90!Black}%
   \fontsize{12}{13}\selectfont%
}
\newcommand{\HexOne}{%
   \color{Purple}%
   \fontsize{12}{13}\selectfont%
}
\newcommand{\HexTwoP}{%
   \color{RedViolet}%
   \fontsize{12}{13}\selectfont%
}
\newcommand{\HexPPP}{%
   \color{VioletRed}%
   \fontsize{11}{12}\selectfont%
}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\newcommand{\cyPen}[1]{{\vphantom{.}\color{Cerulean}#1}}
\newcommand{\redPen}[1]{{\vphantom{.}\color{Red}#1}}

\newenvironment{myIndent}{%
   \begin{adjustwidth}{2.5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myDindent}{%
   \begin{adjustwidth}{5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myTindent}{%
   \begin{adjustwidth}{7.5em}{0em}%
}{%
   \end{adjustwidth}%
}

\newenvironment{myConstrict}{%
   \begin{adjustwidth}{2.5em}{2.5em}%
}{%
   \end{adjustwidth}%
}

\newcommand{\udefine}[1]{{%
   \setulcolor{Red}%
   \setul{0.14em}{0.07em}%
   \ul{#1}%
}}

\newcommand{\uprop}[1]{{%
   \setulcolor{Purple}%
   \setul{0.14em}{0.07em}%
   \ul{#1} 
}}

\newcommand{\blab}[1]{\textbf{#1}}
\newcommand{\blect}[1]{{\color{MidnightBlue}\textbf{#1}}}

\newcommand{\uuline}[2][.]{%
{\vphantom{a}\color{#1}%
\rlap{\rule[-0.18em]{\widthof{#2}}{0.06em}}%
\rlap{\rule[-0.32em]{\widthof{#2}}{0.06em}}}%
#2}

\newcommand{\pprime}{{\prime\prime}}
\newcommand{\suchthat}{ \hspace{0.3em}s.t.\hspace{0.3em}}
\newcommand{\rea}[1]{\mathrm{Re}(#1)}
\newcommand{\ima}[1]{\mathrm{Im}(#1)}
\newcommand{\comp}{\mathsf{C}}
\newcommand{\trans}{\mathsf{T}}
\newcommand{\myHS}{ \hspace{0.5em}}
\newcommand{\gap}{\phantom{2}}

\newcommand{\GenLin}{\ensuremath{\mathrm{GL}}}
\newcommand{\Cay}{\ensuremath{\mathrm{Cay}}}

\newcommand{\myId}{\mathrm{Id}}
\newcommand{\myIm}{\mathrm{im}}
\newcommand{\Obj}{\mathrm{Obj}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\End}{\mathrm{End}}
\newcommand{\Aut}{\mathrm{Aut}}

\newcommand{\df}{\mathrm{d}}
\newcommand{\Df}{\mathrm{D}}

\newcommand{\mcateg}[1]{{\bm{\mathsf{#1}}}}

\newcommand{\mdeg}{\mathrm{mdeg}\phantom{.}}

\newcommand{\dividesDeprecated}{\mathop{\mid}}
\newcommand{\divides}{\mathrel{\mid}}

\newcommand{\card}{\mathrm{card}}
\newcommand{\supp}{\mathrm{supp}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\conv}{\mathrm{conv}}
\newcommand{\opnorm}{\mathrm{op}}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\acc}{\mathrm{acc}}

\newcommand{\mSpan}{\mathrm{span}}
\newcommand{\Interior}{\mathop{\mathrm{Int}}}

\newcommand{\mMat}[1]{\mathbf{#1}}

\newcommand{\NBV}{\ensuremath{\mathrm{NBV}}}
\newcommand{\Acc}{\mathrm{Acc}}
\newcommand{\BV}{\ensuremath{\mathrm{BV}}}
\newcommand{\Var}{\ensuremath{\mathrm{Var}}}

\newcommand{\Alt}{\mathrm{Alt}}
\newcommand{\Sym}{\mathrm{Sym}}

\newcommand{\weakst}{weak$^*$ }

\newcommand{\radtimes}{\mathop{\widehat{\times}}}

\newcommand{\mMod}[1]{\phantom{a}(\mathrel{\mathrm{mod}} #1)}
\newcommand{\Fun}{\mathrm{Fun}}
\newcommand{\act}{\mathrm{act}}
\newcommand{\Fix}{\mathrm{Fix}}
\newcommand{\Sub}{\mathrm{Sub}}
\newcommand{\Cl}{\mathrm{Cl}}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\SL}{\mathrm{SL}}
\newcommand{\PSL}{\mathrm{PSL}}
\newcommand{\core}{\mathrm{core}}
\newcommand{\Syl}{\mathrm{Syl}}
\newcommand{\Iso}{\mathrm{Iso}}
\newcommand{\Homeo}{\mathrm{Homeo}}
\newcommand{\Inn}{\mathrm{Inn}}
\newcommand{\Out}{\mathrm{Out}}
\newcommand{\ab}{\mathrm{ab}}
\newcommand{\Max}{\mathrm{Max}}
\newcommand{\lt}{\mathrm{lt}}
\newcommand{\Nil}{\mathrm{Nil}}
\newcommand{\Ideal}{\mathrm{Ideal}}
\newcommand{\Spec}{\mathrm{Spec}}
\newcommand{\Res}{\mathrm{Res}}
\newcommand{\exConv}{\mathrm{ex}}


\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\Log}{Log}
\DeclareMathOperator{\symdif}{\triangle}
\DeclareMathOperator{\Average}{Average}
\DeclareMathOperator*{\AverageAst}{Average}

% Thank you Gonzalo Medina and Moriambar who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/74125/how-do-i-put-text-over-symbols%
\newcommand{\myequiv}[1]{\stackrel{\mathclap{\mbox{\footnotesize{$#1$}}}}{\equiv}}

% Thank you chs who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/89821/how-to-draw-a-solid-colored-circle%
\newcommand{\filledcirc}[1][.]{\ensuremath{\hspace{0.05em}{\color{#1}\bullet}\mathllap{\circ}\hspace{0.05em}}}

%Thank you blerbl who wrote this on stack exchange:
%https://tex.stackexchange.com/questions/25348/latex-symbol-for-does-not-divide
\newcommand{\ndiv}{\hspace{-0.3em}\not|\hspace{0.35em}}

\newcommand{\mySepOne}[1][.]{%
   {\noindent\color{#1}{\rule{6.5in}{1mm}}}\\%
}
\newcommand{\mySepTwo}[1][.]{%
   {\noindent\color{#1}{\rule{6.5in}{0.5mm}}}\\%
}
\newcommand{\mySepThree}[1][.]{%
   {\noindent\color{#1}{\rule{6in}{0.25mm}}}\\%
}

\newenvironment{myClosureOne}[2][.]{%
   \color{#1}%
   \begin{tabular}{|p{#2in}|} \hline \\%
}{%
   \\ \hline \end{tabular}%
}

\newcommand{\retTwo}{\hfill\bigbreak}

\newcommand{\dispDate}[1]{{
   \color{Black}%
   \fontsize{20}{18}\selectfont%
   #1\retTwo
}}


\begin{document}
\setul{0.14em}{0.07em}
\calibri

\hTwo\dispDate{12/14/2025}

\blect{Math 241a Notes:}\retTwo

Suppose $V$ is a finite dimensional vector space and $\pi: G \to \GL(V)$ is a representation. Then $\pi$ is called \udefine{irreducible} if the only $\pi(G)$-invariant subspaces are $\{0\}$ and $V$. $\pi$ is called \udefine{completely reducible} if $V = \bigoplus V_i$ where $V_i$ is a $\pi(G)$-invariant irreducible subspace.\retTwo

Also if $V = \mathbb{C}^n$ or $\mathbb{R}^n$, then I shall denote $\GL(V)$ as $\GL_n(\mathbb{C})$ or $\GL_n(\mathbb{R})$ respectively. Similarly, I shall denote $U(V)$ as $U(n)$.\retTwo

\exTwo\ul{Proposition 2.2.11:} If $G$ is a group and $\pi: G \to U(n)$ is a unitary representation, then:
\begin{itemize}
	\item[(i)] every $\pi(G)$-invariant subspace has a $\pi(G)$-invariant orthogonal complement.
	\begin{myIndent}\exThreeP
		Proof:\\
		Suppose $V$ is invariant and $w \in V^\perp$. Then as $\pi(g)$ is unitary (which means\\ $\pi(g)^* = \pi(g)^{-1}$) for each $g \in G$, we know:
		
		{\centering$\langle \pi(g)w, v\rangle = \langle w, \pi(g)^* v\rangle = \langle w, \pi(g^{-1})v \rangle = 0$.\retTwo\par}
		
		It follows that $V^\perp$ is $G$-invariant.\retTwo
	\end{myIndent}

	\item[(ii)] $\pi$ is completely reducible.
	\begin{myIndent}\exThreeP
		Proof:\\
		We can prove this by induction. If $\mathbb{C}^n$ isn't irreducible then we can write\\ $\mathbb{C}^n = V \oplus V^\perp \cong \mathbb{C}^{k} \oplus \mathbb{C}^{n-k}$ where both $V$ and $V^\perp$ are $G$-invariant. Then\\ we just repeat this reasoning on the smaller subspaces. $\blacksquare$\retTwo
	\end{myIndent}
\end{itemize}

\ul{Proposition 2.2.12:} If $G$ is a compact group, $V$ is a finite dimensional real or complex\\ Hausdorff topological vector space, and $\pi: G \to \GL(V)$ is a (strong operator) continuous representation, then $\pi$ is completely reducible.
\begin{myIndent}\exThreeP
	Proof:\\
	Using \inLinkRap{G-invariant inner product page 485}{corollary 2.2.8 on page 485}, let $\langle\phantom{.},\phantom{.}\rangle$ be a $G$-invariant inner product on $V$. Then $\pi$ is a unitary representation with respect to this inner product. So, we can apply the prior proposition. $\blacksquare$\retTwo
\end{myIndent}

\hTwo\mySepTwo

Let $\mathcalli{X}$ be a real or complex vector space and let $A \subseteq \mathcalli{X}$ be convex.
\begin{itemize}
	\item Given any $x, y \in \mathcalli{X}$ we let $[x, y] \coloneqq \{ty + (1-t)x : 0 \leq t \leq 1\}$. Also, we let $(x, y) \coloneqq \{ty + (1-t)x : 0 < t < 1\}$. 
	\item We say $x \in A$ is an \udefine{extreme point} if for any $y, z \in A$ we have that $x \in [y, z]$ iff\\ $x = y$ or $x = z$. We denote the set of such points as $\exConv(A)$.
	\item We say $\emptyset \neq B \subseteq A$ is an \udefine{extreme set} if for any $y, z \in A$ we have that:
	
	{\centering$(y, z) \cap B \neq \emptyset \Longrightarrow [y, z] \subseteq B$.\newpage\par}
\end{itemize}

Given a set $E \subseteq \mathcalli{X}$ where $\mathcalli{X}$ is a topological real or complex vector space, we define $\overline{\conv}(A)$ to be the smallest closed convex set containing $A$. This is well-defined because arbitrary intersections of closed convex sets are closed and convex.\retTwo

\pracOne Clearly, if one has a convex polyhedron in $\mathbb{R}^3$, then the faces of the polyhedron are extreme sets and the extreme points are precisely the vertices.\retTwo

\ul{Exercise 2.2.10:} Let $X$ be a compact Hausdorff space and let $M(X)$ denote the set of Radon probability measures on $X$. Then $\exConv(M(X)) = \{\delta_x : x \in X\}$ where $\delta_x$ is the Dirac delta measure at $x$.
\begin{myIndent}\pracTwo
	Proof:\\
	Let $\mu_0$ and $\mu_1$ be probability measures on $X$, and suppose that $\delta_x \in [\mu_0, \mu_1]$. Hence, there exists $t \in [0, 1]$ such that $t\mu_1 + (1 - t)\mu_0 = \delta_x$. If $t = 0$ or $t = 1$, there is nothing to show. So suppose $t \in (0, 1)$. As $\delta_x(\{x\}^\comp) = 0$, we know that $t\mu_1(\{x\}^\comp) = -(1 - t)\mu_0(\{x\}^\comp)$. That said, we also must have that $\mu_1(\{x\}^\comp) \geq 0$ and $\mu_0(\{x\}^\comp) \geq 0$. In turn, the left side of our equation must be nonnegative and the right side must be nonpositive. The only way this works out is if $t\mu_1(\{x\}^\comp) = 0 = -(1 - t)\mu_0(\{x\}^\comp)$. And since $t \neq 0$ and $-(1 - t) \neq 0$, we can conclude that $\mu_1(\{x\}^\comp) = 0 = \mu_0(\{x\}^\comp)$. And now it is clear that $\mu_0 = \delta_x = \mu_1$ since all three have total measure $1$. This proves that $\delta_x \in \exConv(M(X))$ for any Dirac delta measure $\delta_x$.\retTwo

	To show the converse, we first introduce a lemma. Suppose $\nu$ is a Borel Radon probability measure on $X$. Then $\nu(E) \in \{0, 1\}$ for all sets $E \in \mathcalli{B}_X$ if and only if  $\nu$ is a Dirac delta measure.
	\begin{myIndent}\pracTwo
		Proof:\\
		The $(\Longleftarrow)$ claim is obvious. To show the other claim, you could just use the reasoning on \inLinkRap{Pages 444-445 Atomless Measures}{pages 444-445}. However, I wrote a different proof before realizing that.\retTwo
		
		Let $\mathcalli{F}$ be the set of all compact subsets of $X$ with measure $1$. This collection is\\ partially ordered by inclusion, and by Zorn's lemma we can conclude that there is\\ a minimal set $F$ in $\mathcalli{F}$.
		\begin{myIndent}\pracTwo
			Suppose $\mathcalli{F}_0$ is a chain in $\mathcalli{F}$ and let $K^\prime = \bigcap_{K \in \mathcalli{F}_0}$. I claim that $\mu(K^\prime) = 1$. This will be a compact subset of $X$ since it is a closed subset of $X$. We also claim $\mu(K^\prime) = 1$. After all, if not then by the outer regularity of $\mu$ plus the fact that $\mu(E) \in \{0, 1\}$ for all sets $E \in \mathcalli{B}_X$  we know there exists an open set $U \supseteq K^\prime$ with $\mu(U) = 0$. Next, by the compactness of $X$ we know there are finitely many sets $K_1 \supseteq K_2 \supseteq \cdots \supseteq K_n$ in $\mathcalli{F}_0$ such that $X = U \cup \bigcup_{j=1}^n K_j^\comp$. Finally, we know that $K^\prime \neq K_n$ since $\mu(K^\prime) \neq \mu(K_n)$. So, there must exist $K \in \mathcalli{F}_0$ with $K^\prime \subseteq K \subsetneq K_n$. But in turn we must have that $K \subseteq U$. This implies that $\mu(K) = 0$, which is a contradiction as $K \in \mathcalli{F}_0$ means that $\mu(K) = 1$.\retTwo

			We conclude that $K^\prime \in \mathcalli{F}$. And clearly $K^\prime$ is a bound to $\mathcalli{F}_0$.\retTwo
		\end{myIndent}

		Finally, suppose there exists distinct $x, y \in F$. Then we know that $\{x\}$ is a proper compact subset of $F$. Hence, $\mu(\{x\}) = 0$. Also, by similar arguments to before we know that there is an open set $V \supseteq \{x\}$ such that $\mu(V) = 0$. And, by intersecting $V$ with a neighborhood of $x$ not containing $y$ (which we know exists since $X$ is $T_1$), we can assume $y \notin V$. But now $F - V$ is a compact subset of $X$ properly contained in $F$ such that $\mu(F - V) = 1$. This contradicts the minimality of $F$. Hence, we conclude that there does not exist two distinct elements in $F$.\retTwo

		That said, $F$ isn't empty since otherwise we'd have that $\mu(F) = 0$. So, we conclude that $F$ is a singleton $\{x\}$ and $\mu = \delta_x$.\retTwo
	\end{myIndent}

	Now suppose for the sake of contradiction that $\nu$ is any measure in $M(X)$ that isn't a Dirac delta measure. Then by our prior lemma we know that there exists a set $E \subseteq X$ such that $0 < \nu(E) < 1$. In turn, we now know there exists well-defined probability measures $\mu_0(A) \coloneqq (\nu(E))^{-1}\nu(A \cap E)$ and $\mu_1(A) \coloneqq (\nu(X - E))^{-1}\nu(A - E)$ which are distinct from $\nu$. Finally, by setting $t = \nu(X - E)$ we have that $0 < t < 1$ and $\nu(E) = 1 - t$. And then for all $A \in \mathcalli{B}_X$ we have that:

	{\centering\begin{tabular}{l}
		$\nu(A) = \nu(A \cap E) + \nu(A - E) = \nu(E)\mu_0(A) + \nu(X - E)\mu_1(A)$\\ [4pt]
		$\phantom{\nu(A) = \nu(A \cap E) + \nu(A - E)} = (1 - t)\mu_0(A) + t\mu_1(A)$ 
	\end{tabular}\retTwo\par}

	This shows that $\nu \in [\mu_0, \mu_1]$ but $\nu \neq \mu_0$ and $\nu \neq \mu_1$. So, $\nu$ is not an extreme point of $M(X)$ if $\nu$ is not a Dirac delta measure. $\blacksquare$\retTwo
\end{myIndent}

\mySepTwo

\exTwo\ul{Lemma 2.3.5:} Suppose $\mathcalli{X}$ is a locally convex topological real vector space, $A \subseteq \mathcalli{X}$ is closed and convex, and $x \in \mathcalli{X} - A$. Then there exists $f \in \mathcalli{X}^*$ and $c \in \mathbb{R}$ with $f(y) < c < f(x)$ for all $y \in A$.
\begin{myIndent}\exThreeP
	Proof:\\
	Let $U$ be an open neighborhood of $0 \in \mathcalli{X}$ such that $(x + U) \cap A = \emptyset$. By local convexity we can restrict $U$ to a convex open subset containing $0$. And by the reasoning on \inLinkRap{Page 230 definition of balanced sets}{page 230-232}, we can further restrict $U$ to also ensure that $U$ is balanced.\retTwo

	Next note that because $U$ is balanced, we can equivalently say that $x \notin U + A$. But we want slightly more wiggle room so we'll instead consider the set $\frac{1}{2} U + A$. A fact we will use later is that because because $U$ is convex, we have that $\frac{1}{2}U + \frac{1}{2}U \subseteq U$.\retTwo
	
	Note that $\frac{1}{2}U + A$ is open since $\frac{1}{2}U + A = \bigcup_{a \in A}(a + \frac{1}{2}U)$. It's also convex because $t(a_1 + \frac{1}{2}u_1) + (1 - t)(a_0 + \frac{1}{2}u_0) = (ta_1 + (1-t)a_0) + \frac{1}{2}(tu_1 + (1-t)u_0) \in A + \frac{1}{2}U$ for all $t \in [0, 1]$, $a \in A$, and $u \in U$ since both $U$ and $A$ are convex. Going a step further, we can assume without loss of generality that $0 \in \frac{1}{2}U + A$.
	\begin{myIndent}\exPPP
		To see why, note that if $0 \notin \frac{1}{2}U + A$ then we can translate our entire vector space by some fixed $\frac{1}{2}u + a \in U + A$. Then after doing the later reasoning, we will have a\\ linear functional $f$ and $c \in \mathbb{R}$ such that $f(y - (a + \frac{1}{2}u)) < c < f(x - (a + \frac{1}{2}u))$ for all $y \in A$. In turn $f(y - x) < c - f(x - (a + \frac{1}{2}u)) < 0$ and thus:\\ [-8pt]
		
		{\centering$f(y) < c - f(x - (a + \frac{1}{2}u)) + f(x) < f(x)$ for all $y \in A$\\ [6pt]\par}
		
		where $c - f(x - (a + \frac{1}{2}u)) + f(x)$ is another fixed constant in $\mathbb{R}$.\retTwo
	\end{myIndent}

	But now if $p$ is the Minkowski functional associated to $\frac{1}{2}U + A$, we can follow the reasoning on \inLinkRap{Minkowski functional reference}{page 233} to see that $p$ satisfies the triangle inequality and is continuous. And while\newpage $p(cy) \neq |c|p(y)$ if $c$ is negative since $U + A$ isn't balanced, we do at least have that\\ $p(cy) = cp(y)$ if $c \geq 0$.  Hence, we know that $p$ is a well-defined sublinear functional on $\mathcalli{X}$.\retTwo

	Now it's obvious that $p(x) \geq 1$ and that $p(y) \leq 1$ for all $y \in A$. What's less obvious is that these inequalities are strict.
	\begin{itemize}
		\item	To see that $p(x) > 1$, suppose to the contrary that $x \in c(\frac{1}{2}U + A)$ for all $c > 1$. Equivalently, this means that $cx \in \frac{1}{2}U + A$ for all $c < 1$. But now as $cx - x \to 0$ as $c \to 1$ and $\frac{1}{2}U$ is a neighborhood of $0$ in $\mathcalli{X}$, we know that eventaully $cx - x \in \frac{1}{2}U$. So, we can pick $c$ close enough to $1$ such that $cx - x = \frac{1}{2}u^\prime$ for some $u^\prime \in U$. At the same time, as $cx \in \frac{1}{2}U + A$ we know there exists $u \in U$ and $a \in A$ such that $cx = \frac{1}{2}u + a$. Hence, we get a contradiction as:
		
		{\centering$x = \frac{1}{2}u - \frac{1}{2}u^\prime + a \in \frac{1}{2}U + \frac{1}{2}U + A \subseteq U + A$.\retTwo\par}

		\item To see that $p(y) < 1$ for any fixed $y \in A$, note again that because $cy - y \to 0$ as $c \to 1$ and $\frac{1}{2}U$ is a neighborhood of $0$, we know that there is some $\varepsilon_y > 0$ such that $cy - y \in \frac{1}{2}U$ when $c < 1 + \varepsilon_y$. In turn, $cy \in \frac{1}{2}U + y \subseteq \frac{1}{2}U + A$ when $c < 1 + \varepsilon_y$. And finally, we have that $y \in c(\frac{1}{2}U + A)$ if $c > (1 + \varepsilon_y)^{-1}$ where the latter is strictly less than $1$.\retTwo
	\end{itemize}

	Finally, we actually create our linear functional. Let $\mathcalli{M} = \{cx : c \in \mathbb{R}\}$ and then define $g: \mathcalli{M} \to \mathbb{R}$ by $g(cx) = cp(x)$. Then $g$ is a linear functional on the subspace $\mathcalli{M}$. Also since $p(cx) \geq 0 > g(cx)$ when $c < 0$ and we know from the sublinearity of $p$ that $g(cx) = p(cx)$ when $c \geq 0$, we can conclude that $g \leq p$ on $\mathcalli{M}$. So, by the real Hahn-Banach theorem we know there exists a linear functional $f: \mathcalli{X} \to \mathbb{R}$ with $f(y) \leq p(y)$ for all $y \in \mathcalli{X}$ and $f(cx) = g(cx)$ for all $c \in \mathbb{R}$.\retTwo

	Note that $|f(y)| = \max(-f(y), f(y)) = \max(f(-y), f(y)) \leq \max(p(-y), p(y))$ and that $p$ is continuous, meaning that $p(-y) \to 0$ and $p(y) \to 0$ as $y \to 0$. Hence, we can conclude that $f$ is continuous. Also, $f(x) = p(x) > 1 > p(y) \geq f(y)$ for all $y \in A$. $\blacksquare$\retTwo
\end{myIndent}

\ul{Krein-Millman Theorem:} Let $\mathcalli{X}$ be a topological vector space whose topology is defined by a sufficient family of seminorms. If $A \subseteq \mathcalli{X}$ is compact and convex, then $\overline{\conv}(\exConv(A)) = A$.
\begin{myIndent}\exThreeP
	Proof:\\
	Without loss of generality, we may assume $\mathcalli{X}$ is a real vector space.\retTwo

	Claim: If $B$ is a closed convex extreme subset of $A$, then $B \cap \exConv(A) \neq \emptyset$.
	\begin{myIndent}\exPPP
		To prove this we use Zorn's lemma. Let $\mathcalli{F}$ be the collection of all closed convex\\ extreme subsets of $A$. Also partially order $\mathcalli{F}$ by inclusion. Then we claim $\mathcalli{F}$ has a minimal element.
		\begin{myIndent}
			Let $\mathcalli{F}_0$ be a chain in $\mathcalli{F}$ and set $C = \bigcap_{B \in \mathcalli{F}_0} B$. Then $C$ is not empty by the finite intersection property of $A$ (since $A$ is compact). Also $C$ is closed and convex since it is the intersection of closed convex sets. Finally, suppose $y, z \in A$ satisfy that $(y, z) \cap C \neq \emptyset$. Then for any $B \in \mathcalli{F}_0$ we know $(y, z) \cap B \neq \emptyset$. In turn, $[y, z] \subseteq B$ for all $B \in \mathcalli{F}_0$. And this proves that $[y,z] \subseteq C$. All of this shows that $C \in \mathcalli{F}$.\newpage
		\end{myIndent}

		Now let $D$ be a minimal set in $\mathcalli{F}$. If $D$ is a singleton $\{x\}$, then we will be done as $x \in B \cap \exConv(A)$.\retTwo

		Suppose for the sake of contradiction that $x, y$ are distinct elements of $D$. Then by lemma 2.3.5, there exists $f \in \mathcalli{X}^*$ such that $f(x) < f(y)$. Since $D$ is compact, we know that $M = \max\{f(z) : z \in D\}$ exists. So, let $E = \{z \in D : f(z) = M\}$. Then $E$ is a proper subset of $D$ as $x \notin E$. We also claim that $E$ is an extreme set, thus contradicting that minimality of $D$.
		\begin{myIndent}
			$E$ is compact since it is a closed subset of $D$. Also note that $E$ is convex\\ because if $z_0, z_1 \in D$ and $t \in [0, 1]$ then:
			
			{\centering$f(tz_1 + (1 - t)z_0) = tf(z_1) + (1-t)z_0 = tM + (1 - t)M = M$.\retTwo\par}
			
			Finally, suppose $z_0, z_1 \in A$ and $tz_1 + (1 - t)z_0 \in E$ for some $t \in (0, 1)$. As $D \supseteq E$ is an extreme set we must have that $z_0, z_1 \in D$. And now as $M = f(tz_1 + (1- t)z_0) = tf(z_1) + (1 - t)f(z_0)$ and both $f(z_0) \leq M$ and $f(z_1) \leq M$, we must have that $f(z_0) = M = f(z_1)$. So $[z_0, z_1] \subseteq E$.\retTwo
		\end{myIndent}
	\end{myIndent}

	Now it's clear that $\overline{\conv}(\exConv(A)) \subseteq A$ (since $A$ is a closed convex set containing $\exConv(A)$). But suppose for the sake of contradiction that there exists $x \in A$ with $x \notin \overline{\conv}(\exConv(A))$. By lemma 2.3.5. again we can find a linear functional $f \in \mathcalli{X}^*$ such that $f(y) < \alpha < f(x)$ for all $y \in \overline{\conv}(\exConv(A))$ (where $\alpha \in \mathbb{R}$). And since $A$ is compact we know like before that $M = \max\{f(x) : x \in A\}$ exists.\retTwo
	
	By identical reasoning to before we know that $B = \{x \in A : f(x) = M\}$ is an extreme set. So by our claim, we have that $B \cap \exConv(A) \neq \emptyset$. Yet this is a contradiction because $\exConv(A) \subseteq \overline{\conv}(\exConv(A))$ is disjoint from $B$. $\blacksquare$\retTwo
\end{myIndent}

\ul{Obvious Corollary:} If $A$ is a compact convex subset of a topological vector space $\mathcalli{X}$ whose topology is generated by a sufficient family of seminorms, then $\exConv(A) \neq \emptyset$.

\pracOne\mySepTwo

A small lemma worth noting is that if $\mathcalli{X}$ is a topological vector space and $A \subseteq \mathcalli{X}$ is convex, then so is $\overline{A}$.
\begin{myIndent}\pracTwo
	To see this, suppose $x, y \in \overline{A}$. Then we know that there are nets $\langle x_i\rangle_{i \in I}$ and $\langle y_J\rangle_{j \in J}$ contained in $A$ and converging to $x$ and $y$ respectively. In turn, by considering the product net $\langle x_i, y_j\rangle_{I \times J}$ we have for any $t \in [0, 1]$ that $ty_j + (1 - t)x_i \to ty + (1 - t)x$. And since $ty_j + (1 - t)x_i \in A$ for all $(i, j) \in I \times J$ we have shown that $ty + (1 - t)x \in \overline{A}$. So, $\overline{A}$ is convex.\retTwo
\end{myIndent}

Consequently, we always have that $\overline{\conv(E)} \supseteq \overline{\conv}(E)$ for any set $E \subseteq \mathcalli{X}$. And this lets us rephrase the Krein Millman theorem in a slightly more useful way. If $\mathcalli{X}$ is as stated in the theorem and $A \subseteq \mathcalli{X}$ is compact and convex, then $\overline{\conv(\exConv(A))} = A$.

\hTwo\mySepTwo

\dispDate{12/22/2025}

For this section assume that all vector spaces are Banach spaces.\newpage

Suppose $\mathcalli{X}, \mathcalli{Y}$ are Banach spaces. Then a bounded linear operator $T: \mathcalli{X} \to \mathcalli{Y}$ is called \udefine{compact} if $\overline{T(\mathcalli{X}_1)}$ is compact in $\mathcalli{Y}$. (See \inLinkRap{page 469 reference}{page 469} for a reminder of what $\mathcalli{X}_1$ means\dots)\retTwo

\pracOne Note: if $T$ has \underline{finite rank} (meaning $T(\mathcalli{X})$ has finitely many dimensions), then $T$ is compact. 
\begin{myIndent}\pracTwo
	Why?\\
	Since $T(\mathcalli{X})$ is a finite dimensional subspace, we know by (Rudin) Theorem 1.21 on \inLinkRap{Rudin Functional Analysis Theorem 1.21}{page 442} that $T(\mathcalli{X})$ is a closed set. Hence, $C \coloneqq \overline{T(\mathcalli{X}_1)}$ is a closed subset of $T(\mathcalli{X})$. Furthermore, $C \subseteq \{y \in T(\mathcalli{X}) : \|y\| \leq \|T\|_{\opnorm}\}$. So, if we consider any bijective linear isometric map between $\mathbb{C}^n$ (or $\mathbb{R}^n$) and $T(\mathcalli{X})$, then we will get that $C$ is homeomorphic to a closed and bounded subset of $\mathbb{C}^n$ (or $\mathbb{R}^n$). By Heine-Borel we thus have that $C$ is compact. $\blacksquare$\retTwo

	\begin{myIndent}\myComment
		As a side note, you can use similar reasoning to show that any closed and bounded set in a finite dimensioned normed vector space is compact.\retTwo
	\end{myIndent}
\end{myIndent}

\exTwo\ul{Lemma 3.1.3:} Suppose $\{T_n\}_{n \in \mathbb{N}}$ is a sequence of compact maps in $B(\mathcalli{X}, \mathcalli{Y})$ and\\ $\|T_n - T\|_{\opnorm} \to 0$ as $n \to \infty$. Then $T$ is also compact.
\begin{myIndent}\exThreeP
	Proof:\\
	It suffices to prove that $T(\mathcalli{X}_1)$ is totally bounded since that will imply $\overline{T(\mathcalli{X}_1)}$ is totally bounded (and we already have completeness just from the fact it's a closed set in a\\ complete metric space $\mathcalli{Y}$). Note that for all $x, y \in \mathcalli{X}_1$, we have that:

	{\centering\begin{tabular}{l}
		$\|Tx - Ty\| \leq \|Tx - T_nx\| + \|T_nx - T_ny\| + \|T_n y - Ty\|$\\ [4pt]
		$\phantom{\|Tx - Ty\|} \leq \|T - T_n\|_{\opnorm}\|x\| + \|T_nx - T_ny\| + \|T_n - T\|_\opnorm \|y\|$\\ [4pt]
		$\phantom{\|Tx - Ty\|} \leq 2\|T - T_n\|_{\opnorm} + \|T_nx - T_ny\|$.
	\end{tabular} \retTwo\par}

	Given any $\varepsilon > 0$, fix $n$ large enough so that $\|T_n - T\|_{\opnorm} < \sfrac{\varepsilon}{4}$. Then using the fact that $T_n$ is a compact operator, pick $x_1, \ldots, x_m \in \mathcalli{X}_1$ such that any $y \in T_n(\mathcalli{X}_1)$ is within $\sfrac{\varepsilon}{2}$ from some $T_n x_i$. It then follows that any $y \in T(\mathcalli{X}_1)$ is within $\varepsilon$ from some $T x_i$. $\blacksquare$\retTwo
\end{myIndent}

\pracOne\mySepTwo

As an application of the above points, suppose $\mathcalli{H}$ is a Hilbert space with orthonormal basis $\{e_i\}_{i \in I}$ and $T \in B(\mathcalli{H})$ is given by a diagonal matrix $ \begin{bmatrix}
	\phantom{.}\lambda_i\delta_{i,j}\phantom{.}
\end{bmatrix}$ (in other words $Te_i = \lambda e_i$ for all $i \in I$). Then $T$ is compact iff $\{i \in I : |\lambda_i| > \varepsilon\}$ is finite for all $\varepsilon > 0$.
\begin{myIndent}\pracTwo
	\ul{Lemma:} If $S$ is a linear operator on $\mathcalli{H}$ given by a diagonal matrix $ \begin{bmatrix}
	\phantom{.}\mu_i\delta_{i,j}\phantom{.}
	\end{bmatrix}$ where the $\mu_i$ are bounded, then $\|S\|_{\opnorm} = \sup_{i \in I} |\mu_i|$.
	\begin{myIndent}\pracTwo
		Proof:\\
		We can use \inLinkRap{page 284 reference example 1.2.1}{example 1.2.1 on page 284}. Specifically, recall that $\mathcalli{H}$ is unitarily\\ isomorphic to $\ell^2(I)$ by a natural map $U$. Furthermore, $S$ is unitarily equivalent to\\ multiplication by the element $\mu \in \ell^\infty(I)$ where $\mu = \{\mu_i\}_{i \in I}$.
		\begin{myTindent}\myComment
			In other words, $S = U^{-1} M_\mu U$.\retTwo
		\end{myTindent}

		Therefore, we have that $\|S\|_{\opnorm} = \|M_\mu\|_{\opnorm} = \|\mu\|_{\opnorm} = \sup_{i \in I} |\mu_i|$. $\blacksquare$\retTwo
	\end{myIndent}

	$(\Longleftarrow)$\\
	If the latter is true then the set of $i$ for which $\lambda_i \neq 0$ must be countable. Hence we can enumerate those $i$ as $\{i_n\}_{n \in \mathbb{N}} \subseteq I$. Next, for each $n$ we define $T_n$ by letting $T_n e_{i_k} = \lambda_{i_k}$ for all $k \leq n$ and $T_n e_i = 0$ for all other $i \in I$. Then each $T_n$ is bounded with finite rank, and is thus compact. Also, $\|T - T_n\|_{\opnorm} = \sup_{k > n} |\lambda_{i_k}| \to 0$ as $n \to \infty$. So, $T$ is compact.\newpage

	$(\Longrightarrow)$\\
	Suppose that there is some $\varepsilon > 0$ such that $S = \{i \in I : \lambda_i \geq \varepsilon\}$ is an infinite set. Then for all $i, j \in S$ we have that $\|Te_i - Te_j\|^2 = |\lambda_i|^2 + |\lambda_j|^2 \geq 2\varepsilon^2$. So if we pick a nonrepeating sequence $\{e_{i_n}\}_{n \in \mathbb{N}}$ where each $i_n \in S$, then this sequence has no subsequential limits. This proves that $\overline{T(\mathcalli{X}_1)}$ is not compact. $\blacksquare$\retTwo
\end{myIndent}

\mySepTwo

\hTwo Recall from my math 240b notes that if $(X, \mathcal{M}, \mu)$ and $(Y, \mathcal{N}, \nu)$ are $\sigma$-finite measure spaces, $p \in [1, \infty]$, $K$ is a $(\mathcal{M} \otimes \mathcal{N})$-measurable function on $X \times Y$, and there exists $C > 0$ such that $\int |K(x, y)|\df \mu(x) \leq C$ for a.e. $y$ and $\int |K(x, y)|\df \nu(y)$ for a.e. $x$, then we have that $(T_Kf)(x) \coloneqq \int_Y K(x, y)f(y)\df \nu(y)$ is a linear operator in $B(L^p(\nu), L^p(\mu))$ such that $\|T_K\|_{\opnorm} \leq C$.
\begin{myIndent}\hThree
	(This was Folland theorem 6.18).\retTwo
\end{myIndent}

The following theorem goes into more depth on this linear operator.\retTwo

\exTwo\ul{Theorem 3.1.5:} Let $X$ and $Y$ be LCH spaces with $\sigma$-finite Borel measure $\mu$ and $\nu$. Also assume $\mu$ and $\nu$ are finite on compact sets. If $K \in C_c(X \times Y)$ and $p \in [1, \infty]$ then the integral operator $T_K: L^p(\nu) \to L^p(\mu)$ is compact.
\begin{myIndent}\exThreeP
	Proof:\\
	Firstly, recall (Folland) proposition 7.22 on \inLinkRap{Folland Proposition 7.21 page 183}{pages 183-184} to see that $K$ is $(\mathcal{M} \otimes \mathcal{N})$-\\measurable. Furthermore, let $U\subseteq X$ and $V \subseteq Y$ be precompact open sets such\\ that $\supp(K) \subseteq U \times V$. Then given any $\widetilde{K} \in C_c(X, Y)$ with $\supp(\widetilde{K}) \subseteq U \times V$,\\ we have that:

	{\center $\int |\widetilde{K}(x, y)|\df \nu(y)  \leq \|\widetilde{K}\|_u \nu(\overline{V})$ and $\int |\widetilde{K}(x, y)|\df \mu(x)  \leq \|\widetilde{K}\|_u \mu(\overline{U})$ \retTwo\par}

	Therefore, for all $\widetilde{K} \in C_c(X, Y)$ with $\supp(\widetilde{K}) \subseteq U \times V$, we have that:
	
	{\centering$\|T_{\widetilde{K}}\|_{\opnorm} \leq \|\widetilde{K}\|_u \cdot \max(\mu(\overline{U}), \nu(\overline{V}))$.\retTwo\par}

	But also note by (Folland) proposition 7.21 (also on \inLinkRap{Folland Proposition 7.21 page 183}{page 183}) that there is a sequence of functions $\{K_n\}_{n \in \mathbb{N}}$ in $C_c(X)$ converging uniformly to $K$ and satisfying for all $n \in \mathbb{N}$ that:
	\begin{itemize}
		\item $\supp(K_n) \subseteq U \times V$
		\item there exists $m \in \mathbb{N}$ such that $K_n(x, y) = \sum_{i=1}^m  \phi(x)\psi(y)$ where $\phi_i \in C_c(X)$ and $\psi_i \in C_c(Y)$ for all $i \in \{1, \ldots, n\}$.\retTwo
	\end{itemize}
	
	Importantly, note that $(T_{K_n} f)(x) = \sum_{i=1}^n (\int_X \psi_i f \df \mu) \phi_i(x)$. It thus follows that each $T_{K_n}$ is a bounded linear operator with finite rank. Additionally,
	
	{\centering$\|T_K - T_{K_n}\|_{\opnorm} = \|T_{(K - K_n)}\|_{\opnorm} \leq \|K - K_n\|_u \cdot \max(\mu(\overline{U}), \nu(\overline{V})) \to 0$ as $n \to \infty$.\retTwo\par}

	By lemma 3.1.3 we thus know that $T_K$ is compact. $\blacksquare$\retTwo
\end{myIndent}

\hTwo There are some other theorems for determining when an integral operator\\ $T_K f(x) = \int K(x, y)f(y)\df \nu(y)$ is a well-defined bounded map.\newpage

\exTwo\ul{Example 1.2.14:} Let $p \in [1, \infty)$. Then suppose $(X, \mu)$ and $(Y, \nu)$ are $\sigma$-finite measure spaces and $K \in L^p(X \times Y, \mu \times \nu)$. If $q$ is the conjugate exponent of $p$, then we have that $T_K : L^q(Y) \to L^p(X)$ defined by $(T_K f)(x) = \int_Y K(x, y)f(y)\df \nu(y)$ is a bounded linear map with $\|T_K\|_{\opnorm} \leq \|K\|_{L^p(X \times Y)}$.

\begin{myIndent}\exThreeP
	This is because for all $f \in L^q(Y)$:\\ [-24pt]

	{\center\begin{tabular}{l}
		$\|T_K f\|_p^p = \int | \int K(x, y)f(y)\df \nu(y)|^p\df \mu(x)$\\[4pt]
		$\phantom{\|T_K f\|_p^p} \leq \int \left( \int |K(x, y)f(y)|\df \nu(y)\right)^{p} \df \mu(x)$\\ [4pt]
		$\phantom{\|T_K f\|_p^p} \leq \int \left(\int |K(x, y)|^p\df \nu(y)\right)^{p/p} \cdot \|f\|_q^p\df \mu(x) = \|f\|_q^p \iint |K(x, y)|^p \df \nu(y) \df \mu(x)$\\ [4pt]
		$\phantom{\|T_K f\|_p^p \leq \int \left(\int |K(x, y)|^p\df \nu(y)\right)^{p/p} \cdot \|f\|_q^p\df \mu(x)} = \|f\|_q^p\|K\|_{L^p(X \times Y)}^p$
	\end{tabular}\retTwo\par}
\end{myIndent}

\hTwo\mySepTwo





% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\hypertarget{Page 378 Reference}{}
\hypertarget{Math 200a Set 4 Problem 3}{}


\hypertarget{Generalization page 189}{} 


\hypertarget{Math 200a problem set 2 what is a commutator and derived subgroup}{}



\hypertarget{Folland Proposition 11.2}{}
\hypertarget{Folland Lemma 7.15 reference}{}
\hypertarget{Folland Proposition 11.4(b)}{}

\hypertarget{Alireza lemma page 257}{}

\hypertarget{page 337 reference}{}

\hypertarget{Folland Proposition 10.1}{}


\hypertarget{Folland proposition 11.1}{}

\hypertarget{Ergodic reading group notes 3}{}

\hypertarget{existence and uniqueness diff eq notes}{}
\hypertarget{math 241a lecture 5}{}
\hypertarget{idk reference 2}{}

\hypertarget{idk reference 5}{}
\hypertarget{idk reference 6}{}

\end{document}


% \blect{Math 220 Homework:}\\

% \blab{Exercise III.2.2:} Prove that if $b_n, a_n$ are real and positive, $0 < b = \lim_{n \to \infty} b_n$, and $a = \limsup_{n \to \infty} a_n$, then $ab = \limsup_{n \to \infty} (a_nb_n)$.

% \begin{myIndent}\HexOne

% \end{myIndent}



% \hTwo Suppose $|G| = pq$ where $p < q$ are prime numbers. Then $s_q = 1$. Hence there exists a unique Sylow $q$-subgroup $Q$. Furthermore, $Q \lhd G$ and $Q$ is cylic with order $q$.\retTwo

% Next, let $P$ by a Sylow $p$-subgroup. Then because $Q \lhd G$, we have that $PQ < G$. Also, $|P \cap Q| \dividesDeprecated \gcd(p, q) = 1$. So, $P \cap Q = \{1\}$ and from there it follows that $|PQ| = pq = |G|$. So $G / Q = PQ / Q \cong P / (P \cap Q) \cong P$.

